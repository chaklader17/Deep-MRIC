
# ğŸ§  Brain Tumor Detection & Classification using Deep Learning  
Automated MRI Analysis Using CNN, RNN-LSTM, RNN-GRU, K-Means, and YOLOv8

This project provides a comprehensive deep-learning pipeline for analyzing Brain Tumors (BT) from MRI scans. The system can classify brain MRI images into 4 categories:

- **NO_TUMOR**: Healthy brain (no tumor detected)
- **GLIOMA**: Glioma tumor type
- **MENINGIOMA**: Meningioma tumor type
- **PITUITARY**: Pituitary tumor type

## ğŸ¯ Project Overview

This project implements multiple deep learning models for brain tumor classification:

1. **CNN (Convolutional Neural Network)** - Custom CNN architecture for image classification
2. **RNN-LSTM (Recurrent Neural Network with LSTM)** - Hybrid CNN-LSTM model combining spatial feature extraction with sequential processing
3. **RNN-GRU (Recurrent Neural Network with GRU)** - Hybrid CNN-GRU model (faster and more efficient than LSTM)
4. **K-Means Clustering** - Unsupervised clustering for pattern discovery
5. **YOLOv8** - Object detection and localization with bounding boxes

The system provides comprehensive evaluation metrics including confusion matrices, classification reports, and training visualizations for reporting purposes.

## ğŸ”„ Project Workflow

```
1. Data Preparation
   â””â”€â”€> Organize raw MRI images into class folders
   â””â”€â”€> Run preprocessing script/notebook
   â””â”€â”€> Generate train/val/test splits

2. Data Augmentation (Recommended)
   â””â”€â”€> Run augment_training_data.py
   â””â”€â”€> Generate augmented training images (6x dataset size)
   â””â”€â”€> Create augmented_dataset_metadata.csv
   â””â”€â”€> All training notebooks automatically use augmented data

3. Model Training (Choose one or more)
   â”œâ”€â”€> train_cnn.ipynb
   â”‚    â””â”€â”€> Train CNN model
   â”‚    â””â”€â”€> Generate evaluation metrics
   â”‚    â””â”€â”€> Save model and visualizations to models/cnn/
   â”‚
   â”œâ”€â”€> train_rnn_lstm.ipynb
   â”‚    â””â”€â”€> Train CNN-LSTM hybrid model
   â”‚    â””â”€â”€> Generate evaluation metrics
   â”‚    â””â”€â”€> Save model and visualizations to models/rnn_lstm/
   â”‚
   â”œâ”€â”€> train_gru.ipynb
   â”‚    â””â”€â”€> Train CNN-GRU hybrid model
   â”‚    â””â”€â”€> Generate evaluation metrics
   â”‚    â””â”€â”€> Save model and visualizations to models/gru/
   â”‚
   â”œâ”€â”€> train_kmeans.ipynb
   â”‚    â””â”€â”€> Train K-Means clustering model
   â”‚    â””â”€â”€> Generate clustering analysis and visualizations
   â”‚    â””â”€â”€> Save model and results to models/kmeans/
   â”‚
   â””â”€â”€> train_yolov8.ipynb
        â””â”€â”€> Train YOLOv8 detection model
        â””â”€â”€> Generate detection metrics
        â””â”€â”€> Save model and results to models/yolov8/

4. Model Evaluation
   â””â”€â”€> Compare test accuracy
   â””â”€â”€> Review confusion matrices
   â””â”€â”€> Analyze classification reports
   â””â”€â”€> Compare training curves

5. Reporting
   â””â”€â”€> Use generated plots and metrics
   â””â”€â”€> Include in research reports/presentations
```

---

## ğŸ“Œ Features  
- âœ” **CNN Model** - Custom convolutional neural network for brain tumor classification
- âœ” **RNN-LSTM Hybrid Model** - CNN feature extractor + LSTM sequential processing
- âœ” **RNN-GRU Hybrid Model** - CNN feature extractor + GRU sequential processing (faster than LSTM)
- âœ” **K-Means Clustering** - Unsupervised clustering for pattern discovery
- âœ” **YOLOv8** - Tumor detection and localization with bounding boxes
- âœ” **Data Augmentation Pipeline** - Automated augmentation script to create larger training datasets (6x size)
- âœ” Comprehensive evaluation metrics (Accuracy, Precision, Recall, F1-Score)
- âœ” Confusion matrices and classification reports
- âœ” Training/validation curves visualization
- âœ” Sample predictions visualization
- âœ” GPU-accelerated training support (CUDA)
- âœ” Jupyter notebook-based training pipeline
- âœ” Cross-platform support (Windows & Linux)  

---

## ğŸ“ Project Structure

```
Deep-MRIC/
â”œâ”€â”€ data/
â”‚   â”œâ”€â”€ raw_dataset/              # Raw MRI images organized by class
â”‚   â”‚   â”œâ”€â”€ NO_TUMOR/
â”‚   â”‚   â”œâ”€â”€ GLIOMA/
â”‚   â”‚   â”œâ”€â”€ MENINGIOMA/
â”‚   â”‚   â””â”€â”€ PITUITARY/
â”‚   â”œâ”€â”€ vgg16_classification/     # Preprocessed images (generated after preprocessing)
â”‚   â”‚   â”œâ”€â”€ train/                # Original training images
â”‚   â”‚   â”œâ”€â”€ train_augmented/       # Augmented training images (generated by augment_training_data.py)
â”‚   â”‚   â”œâ”€â”€ val/
â”‚   â”‚   â””â”€â”€ test/
â”‚   â”œâ”€â”€ dataset_metadata.csv           # Original dataset metadata
â”‚   â”œâ”€â”€ augmented_dataset_metadata.csv # Augmented dataset metadata (generated by augment_training_data.py)
â”‚   â””â”€â”€ yolov8/                   # YOLOv8 dataset (if using detection)
â”‚       â”œâ”€â”€ images/
â”‚       â””â”€â”€ labels/
â”œâ”€â”€ models/                        # Saved model checkpoints (generated after training)
â”‚   â”œâ”€â”€ cnn/                       # CNN model outputs
â”‚   â”‚   â”œâ”€â”€ cnn_brain_tumor_classifier.pth
â”‚   â”‚   â”œâ”€â”€ cnn_training_history.csv
â”‚   â”‚   â””â”€â”€ [evaluation plots and reports]
â”‚   â”œâ”€â”€ rnn_lstm/                  # RNN-LSTM model outputs
â”‚   â”‚   â”œâ”€â”€ rnn_lstm_brain_tumor_classifier.pth
â”‚   â”‚   â”œâ”€â”€ rnn_lstm_training_history.csv
â”‚   â”‚   â””â”€â”€ [evaluation plots and reports]
â”‚   â”œâ”€â”€ gru/                       # RNN-GRU model outputs
â”‚   â”‚   â”œâ”€â”€ gru_brain_tumor_classifier.pth
â”‚   â”‚   â”œâ”€â”€ gru_training_history.csv
â”‚   â”‚   â””â”€â”€ [evaluation plots and reports]
â”‚   â”œâ”€â”€ kmeans/                    # K-Means clustering outputs
â”‚   â”‚   â”œâ”€â”€ kmeans_clusterer.pkl
â”‚   â”‚   â”œâ”€â”€ kmeans_results.csv
â”‚   â”‚   â””â”€â”€ visualizations/
â”‚   â””â”€â”€ yolov8/                    # YOLOv8 detection outputs
â”‚       â””â”€â”€ yolov8_tumor_detection/
â”œâ”€â”€ preprocess_vgg16.py           # Python script for data preprocessing
â”œâ”€â”€ preprocess_vgg16.ipynb         # Jupyter notebook for interactive preprocessing
â”œâ”€â”€ augment_training_data.py       # Data augmentation script (creates augmented training images)
â”œâ”€â”€ prepare_yolo_dataset.py        # YOLOv8 dataset preparation script
â”œâ”€â”€ train_cnn.ipynb                # CNN model training notebook
â”œâ”€â”€ train_rnn_lstm.ipynb          # RNN-LSTM model training notebook
â”œâ”€â”€ train_gru.ipynb                # RNN-GRU model training notebook
â”œâ”€â”€ train_kmeans.ipynb             # K-Means clustering training notebook
â”œâ”€â”€ train_yolov8.ipynb             # YOLOv8 detection training notebook
â”œâ”€â”€ requirements.txt               # pip requirements (Windows & Linux compatible)
â”œâ”€â”€ environment.yml                # conda environment file (Windows & Linux compatible)
â””â”€â”€ README.md
```

---

# ğŸš€ Getting Started

## 1ï¸âƒ£ Prerequisites  

### System Requirements
- **Python**: 3.8 to 3.11 (3.8+ recommended)
- **Operating System**: Windows 10/11 or Linux (Ubuntu 18.04+)
- **RAM**: Minimum 8GB (16GB recommended for training)
- **Storage**: At least 5GB free space for datasets and models
- **GPU**: NVIDIA GPU with CUDA support (recommended for faster training, but CPU training is also supported)

### Software Requirements
- **Git** - For cloning the repository
- **pip** or **conda** - Package manager
- **Jupyter Notebook** - For running training notebooks (included in installation)

### GPU Setup (Optional but Recommended)
- **NVIDIA GPU** with CUDA Compute Capability 3.5+
- **CUDA Toolkit** 11.0 or higher
- **cuDNN** (included with PyTorch installation)

---

## 2ï¸âƒ£ Installation

This project supports multiple training models: **CNN**, **RNN-LSTM**, **K-Means Clustering**, and **YOLOv8**. All dependencies are included in the installation.

### Option A: Using conda (Recommended - Works on both Windows & Linux)

Conda is recommended as it handles all dependencies including PyTorch, CUDA, and other packages automatically.

#### Windows Installation:

1. **Open Anaconda Prompt or Command Prompt**

2. **Clone the repository:**
```cmd
git clone https://github.com/chaklader17/Deep-MRIC.git
cd Deep-MRIC
```

3. **Create conda environment from environment.yml:**
```cmd
conda env create -f environment.yml
```

4. **Activate the environment:**
```cmd
conda activate deep-mric
```

5. **Verify installation:**
```cmd
python --version
conda list
```

**Note:** The `environment.yml` file includes all dependencies needed for:
- Data preprocessing (`preprocess_vgg16.py`)
- Data augmentation (`augment_training_data.py`)
- CNN training (`train_cnn.ipynb`)
- RNN-LSTM training (`train_rnn_lstm.ipynb`)
- RNN-GRU training (`train_gru.ipynb`)
- K-Means clustering (`train_kmeans.ipynb`)
- YOLOv8 detection (`train_yolov8.ipynb`)

If you need PyTorch with CUDA support, install it separately:
```cmd
conda install pytorch torchvision torchaudio pytorch-cuda=11.8 -c pytorch -c nvidia
```

#### Linux Installation:

1. **Open Terminal**

2. **Clone the repository:**
```bash
git clone https://github.com/chaklader17/Deep-MRIC.git
cd Deep-MRIC
```

3. **Create conda environment from environment.yml:**
```bash
conda env create -f environment.yml
```

4. **Activate the environment:**
```bash
conda activate deep-mric
```

5. **Verify installation:**
```bash
python3 --version
conda list
```

**Note:** The `environment.yml` file includes all dependencies needed for all training notebooks and data augmentation.

If you need PyTorch with CUDA support, install it separately:
```bash
conda install pytorch torchvision torchaudio pytorch-cuda=11.8 -c pytorch -c nvidia
```

### Option B: Using pip (Alternative method)

#### Windows Installation:

1. **Open Command Prompt or PowerShell**

2. **Clone the repository:**
```cmd
git clone https://github.com/chaklader17/Deep-MRIC.git
cd Deep-MRIC
```

3. **Create virtual environment:**
```cmd
python -m venv venv
```

4. **Activate virtual environment:**
```cmd
venv\Scripts\activate
```

5. **Upgrade pip:**
```cmd
python -m pip install --upgrade pip
```

6. **Install PyTorch (CPU or CUDA):**
   - **For CPU only:**
   ```cmd
   pip install torch torchvision torchaudio
   ```
   - **For CUDA support:** Visit [PyTorch Installation](https://pytorch.org/get-started/locally/) and select your CUDA version
   - Example for CUDA 11.8:
   ```cmd
   pip install torch torchvision torchaudio --index-url https://download.pytorch.org/whl/cu118
   ```

7. **Install all other dependencies:**
```cmd
pip install -r requirements.txt
```

#### Linux Installation:

1. **Open Terminal**

2. **Clone the repository:**
```bash
git clone https://github.com/chaklader17/Deep-MRIC.git
cd Deep-MRIC
```

3. **Create virtual environment:**
```bash
python3 -m venv venv
```

4. **Activate virtual environment:**
```bash
source venv/bin/activate
```

5. **Upgrade pip:**
```bash
python -m pip install --upgrade pip
```

6. **Install PyTorch (CPU or CUDA):**
   - **For CPU only:**
   ```bash
   pip install torch torchvision torchaudio
   ```
   - **For CUDA support:** Visit [PyTorch Installation](https://pytorch.org/get-started/locally/) and select your CUDA version
   - Example for CUDA 11.8:
   ```bash
   pip install torch torchvision torchaudio --index-url https://download.pytorch.org/whl/cu118
   ```

7. **Install all other dependencies:**
```bash
pip install -r requirements.txt
```

### Verify Installation

After installation, verify that all packages are correctly installed:

#### Windows:
```cmd
# Check Python version (should be 3.8+)
python --version

# Check if all key packages are installed
python -c "import cv2, numpy, sklearn, tqdm, torch, torchvision, pandas, seaborn, ultralytics, PIL; print('All packages installed successfully!')"

# Check PyTorch and CUDA
python -c "import torch; print(f'PyTorch version: {torch.__version__}'); print(f'CUDA available: {torch.cuda.is_available()}'); print(f'CUDA version: {torch.version.cuda if torch.cuda.is_available() else \"N/A\"}')"

# Check YOLOv8
python -c "from ultralytics import YOLO; print('YOLOv8 installed successfully!')"

# For Jupyter notebook support
jupyter --version
```

#### Linux:
```bash
# Check Python version (should be 3.8+)
python3 --version

# Check if all key packages are installed
python3 -c "import cv2, numpy, sklearn, tqdm, torch, torchvision, pandas, seaborn, ultralytics, PIL; print('All packages installed successfully!')"

# Check PyTorch and CUDA
python3 -c "import torch; print(f'PyTorch version: {torch.__version__}'); print(f'CUDA available: {torch.cuda.is_available()}'); print(f'CUDA version: {torch.version.cuda if torch.cuda.is_available() else \"N/A\"}')"

# Check YOLOv8
python3 -c "from ultralytics import YOLO; print('YOLOv8 installed successfully!')"

# For Jupyter notebook support
jupyter --version
```

### Running Training Notebooks

Once installation is complete, you can run any of the training notebooks:

#### Windows:
```cmd
# Make sure environment is activated
conda activate deep-mric  # or: venv\Scripts\activate

# Start Jupyter Notebook
jupyter notebook
```

Then open any of these notebooks in Jupyter:
- `train_cnn.ipynb` - Train CNN model
- `train_rnn_lstm.ipynb` - Train RNN-LSTM model
- `train_kmeans.ipynb` - Train K-Means clustering
- `train_yolov8.ipynb` - Train YOLOv8 detection model

#### Linux:
```bash
# Make sure environment is activated
conda activate deep-mric  # or: source venv/bin/activate

# Start Jupyter Notebook
jupyter notebook
```

Then open any of these notebooks in Jupyter:
- `train_cnn.ipynb` - Train CNN model
- `train_rnn_lstm.ipynb` - Train RNN-LSTM model
- `train_kmeans.ipynb` - Train K-Means clustering
- `train_yolov8.ipynb` - Train YOLOv8 detection model

**Note:** Each model saves to its own directory (`models/cnn/`, `models/rnn_lstm/`, `models/kmeans/`, `models/yolov8/`), so you can train all models without conflicts.

---

## 3ï¸âƒ£ Data Preprocessing

Before training any model, you need to preprocess your raw MRI images. The preprocessing script will:
- Crop brain regions (remove black background using contour detection)
- Resize images to 224Ã—224 (standard input size for deep learning models)
- Perform stratified train/val/test split (70/15/15) to ensure balanced class distribution
- Create organized directory structure for easy data loading

### Step 1: Organize Raw Data

Place your raw MRI images in the following structure:

```
data/raw_dataset/
â”œâ”€â”€ NO_TUMOR/
â”‚   â”œâ”€â”€ image1.jpg
â”‚   â”œâ”€â”€ image2.png
â”‚   â””â”€â”€ ...
â”œâ”€â”€ GLIOMA/
â”‚   â”œâ”€â”€ image1.jpg
â”‚   â””â”€â”€ ...
â”œâ”€â”€ MENINGIOMA/
â”‚   â””â”€â”€ ...
â””â”€â”€ PITUITARY/
    â””â”€â”€ ...
```

**Supported image formats:** `.jpg`, `.jpeg`, `.png`

### Step 2: Run Preprocessing

#### Option A: Using Python Script

**Windows:**
```cmd
# Make sure virtual environment is activated
venv\Scripts\activate

# Run preprocessing script
python preprocess_vgg16.py
```

**Linux:**
```bash
# Make sure virtual environment is activated
source venv/bin/activate

# Run preprocessing script
python3 preprocess_vgg16.py
```

#### Option B: Using Jupyter Notebook (Interactive)

**Windows:**
```cmd
# Activate virtual environment
venv\Scripts\activate

# Start Jupyter Notebook
jupyter notebook

# Open preprocess_vgg16.ipynb and run all cells
```

**Linux:**
```bash
# Activate virtual environment
source venv/bin/activate

# Start Jupyter Notebook
jupyter notebook

# Open preprocess_vgg16.ipynb and run all cells
```

The preprocessing will create the following structure:

```
data/vgg16_classification/
â”œâ”€â”€ train/
â”‚   â”œâ”€â”€ NO_TUMOR/
â”‚   â”œâ”€â”€ GLIOMA/
â”‚   â”œâ”€â”€ MENINGIOMA/
â”‚   â””â”€â”€ PITUITARY/
â”œâ”€â”€ val/
â”‚   â””â”€â”€ [same class folders]
â””â”€â”€ test/
    â””â”€â”€ [same class folders]
```

**Note:** You can modify the configuration in the script/notebook:
- `RAW_DATA_DIR`: Input directory path (default: `data/raw_dataset/`)
- `VGG_OUTPUT_DIR`: Output directory path (default: `data/vgg16_classification/`)
- `SPLIT_RATIO`: Train/Val/Test split ratios (default: [0.70, 0.15, 0.15])
- `CLASSES`: List of class names (default: ['NO_TUMOR', 'GLIOMA', 'MENINGIOMA', 'PITUITARY'])

**After preprocessing**, you'll have:
- Organized train/val/test splits in `data/vgg16_classification/`
- `data/dataset_metadata.csv` with image paths and labels
- Ready-to-use dataset for training

### Step 3: Data Augmentation (Recommended)

To create a larger training dataset, run the augmentation script:

**Windows:**
```cmd
python augment_training_data.py
```

**Linux:**
```bash
python3 augment_training_data.py
```

This script will:
- Load images from `data/vgg16_classification/train/`
- Apply comprehensive augmentation transforms (rotation, flipping, color jitter, affine, blur, etc.)
- Create 5 augmented versions per original image (configurable)
- Save all augmented images to `data/vgg16_classification/train_augmented/`
- Generate `data/augmented_dataset_metadata.csv` with metadata for all augmented images

**After augmentation**, you'll have:
- Augmented training images in `data/vgg16_classification/train_augmented/` (6x larger dataset)
- `data/augmented_dataset_metadata.csv` with paths, labels, and augmentation types
- All training notebooks will automatically use the augmented data

**Note:** The augmentation script creates multiple versions of each training image, significantly increasing the effective training set size and improving model generalization.

---

# ğŸ“¦ Dataset Setup

## A) VGG16 Classification

After running the preprocessing script (`preprocess_vgg16.py` or `preprocess_vgg16.ipynb`), your data will be organized as:

```
data/vgg16_classification/
â”œâ”€â”€ train/
â”‚   â”œâ”€â”€ NO_TUMOR/
â”‚   â”œâ”€â”€ GLIOMA/
â”‚   â”œâ”€â”€ MENINGIOMA/
â”‚   â””â”€â”€ PITUITARY/
â”œâ”€â”€ val/
â”‚   â”œâ”€â”€ NO_TUMOR/
â”‚   â”œâ”€â”€ GLIOMA/
â”‚   â”œâ”€â”€ MENINGIOMA/
â”‚   â””â”€â”€ PITUITARY/
â””â”€â”€ test/
    â”œâ”€â”€ NO_TUMOR/
    â”œâ”€â”€ GLIOMA/
    â”œâ”€â”€ MENINGIOMA/
    â””â”€â”€ PITUITARY/
```

**Note:** If you already have preprocessed data in a different structure, you may need to adjust the paths in your training scripts.

---

## B) YOLOv8 Detection

YOLO expects:

### Image folders:

```
data/yolov8/images/train/
data/yolov8/images/val/
```

### Label folders (same filenames, `.txt` format):

```
data/yolov8/labels/train/
data/yolov8/labels/val/
```

### Example YOLO label:

```
0 0.52 0.41 0.33 0.44
```

### tumor_data.yaml:

```yaml
train: data/yolov8/images/train
val: data/yolov8/images/val

nc: 1
names: ["tumor"]
```

---

# ğŸ”¥ Training

## How the Project Works

### Workflow Overview:

1. **Data Preprocessing** â†’ Organize and preprocess raw MRI images
2. **Data Augmentation** â†’ Generate augmented training images (recommended, creates 6x larger dataset)
3. **Model Training** â†’ Train any combination of models:
   - CNN (supervised classification)
   - RNN-LSTM (supervised classification)
   - K-Means (unsupervised clustering)
   - YOLOv8 (object detection)
4. **Model Evaluation** â†’ Generate confusion matrices, classification reports, and visualizations
5. **Model Comparison** â†’ Compare performance metrics between different models

### Available Training Notebooks:

| Notebook | Model Type | Output Directory | Description |
|----------|------------|-----------------|-------------|
| `train_cnn.ipynb` | Supervised Classification | `models/cnn/` | Custom CNN architecture for image classification |
| `train_rnn_lstm.ipynb` | Supervised Classification | `models/rnn_lstm/` | Hybrid CNN-LSTM model for sequential feature processing |
| `train_gru.ipynb` | Supervised Classification | `models/gru/` | Hybrid CNN-GRU model (faster and more efficient than LSTM) |
| `train_kmeans.ipynb` | Unsupervised Clustering | `models/kmeans/` | K-Means clustering for pattern discovery |
| `train_yolov8.ipynb` | Object Detection | `models/yolov8/` | YOLOv8 for tumor detection with bounding boxes |

### Training Process:

**For CNN, RNN-LSTM, and RNN-GRU notebooks:**
1. **Data Loading**: Load preprocessed images from `data/vgg16_classification/`
   - Automatically uses `train_augmented/` directory if available (created by `augment_training_data.py`)
   - Falls back to `train/` directory if augmented data not found
2. **Data Augmentation**: Pre-applied via `augment_training_data.py` (creates 6x larger training set)
3. **Model Definition**: Define CNN, CNN-LSTM, or CNN-GRU architecture
4. **Training Loop**: Train model with validation monitoring
5. **Model Saving**: Save best model based on validation accuracy
6. **Evaluation**: Test on test set and generate metrics (accuracy, classification report, confusion matrix)
7. **Visualization**: Create plots for training curves, confusion matrices, and sample predictions

**For K-Means notebook:**
1. **Data Loading**: Load images and extract features
2. **Feature Extraction**: Flatten images and apply PCA (optional)
3. **Clustering**: Apply K-Means algorithm
4. **Evaluation**: Calculate silhouette score, inertia, and Adjusted Rand Index
5. **Visualization**: Create cluster visualizations, confusion matrix, and elbow method plots

**For YOLOv8 notebook:**
1. **Dataset Check**: Verify YOLOv8 dataset structure
2. **Model Initialization**: Load pre-trained YOLOv8 model
3. **Training**: Train with validation monitoring
4. **Evaluation**: Calculate mAP, precision, and recall metrics
5. **Testing**: Test on sample images with bounding box predictions

---

## 1ï¸âƒ£ Train CNN Model

**Important:** 
- Make sure you've run the preprocessing script first (see [Data Preprocessing](#3ï¸âƒ£-data-preprocessing) section)
- For best results, run `augment_training_data.py` to create augmented training data (see [Data Augmentation](#step-3-data-augmentation-recommended) section)

### Windows & Linux:

**Using Conda (Recommended):**
```cmd
# Windows
conda activate deep-mric
jupyter notebook

# Linux
conda activate deep-mric
jupyter notebook
```

**Using pip/venv:**
```cmd
# Windows
venv\Scripts\activate
jupyter notebook

# Linux
source venv/bin/activate
jupyter notebook
```

Then:
1. **Open `train_cnn.ipynb`** in the browser
2. **Run all cells** (Cell â†’ Run All) or run cells sequentially

### What the Notebook Does:

- Loads and preprocesses data with augmentation
- Defines a custom CNN architecture (4 convolutional blocks + fully connected layers)
- Trains the model with early stopping and learning rate scheduling
- Evaluates on test set and generates:
  - Confusion matrix
  - Classification report (precision, recall, F1-score)
  - Training/validation curves
  - Sample predictions visualization
- Saves model to `models/cnn/cnn_brain_tumor_classifier.pth`
- Saves all outputs (curves, confusion matrix, reports) to `models/cnn/`

---

## 2ï¸âƒ£ Train RNN-LSTM Model

The RNN-LSTM notebook trains a hybrid CNN-LSTM model that combines:
- **CNN layers** for spatial feature extraction
- **LSTM layers** for sequential processing of features

**Important:** Make sure you've run the preprocessing script first. For best results, also run `augment_training_data.py` to create augmented training data.

### Windows & Linux:

**Using Conda (Recommended):**
```cmd
# Windows
conda activate deep-mric
jupyter notebook

# Linux
conda activate deep-mric
jupyter notebook
```

**Using pip/venv:**
```cmd
# Windows
venv\Scripts\activate
jupyter notebook

# Linux
source venv/bin/activate
jupyter notebook
```

Then:
1. **Open `train_rnn_lstm.ipynb`** in the browser
2. **Run all cells** (Cell â†’ Run All)

### What the Notebook Does:

- Loads and preprocesses data (same as CNN notebook)
- Defines CNN-LSTM hybrid architecture:
  - CNN feature extractor (3 convolutional blocks)
  - LSTM layers to process CNN features as sequences
  - Fully connected layers for classification
- Trains the model with the same training pipeline as CNN
- Generates the same evaluation metrics and visualizations
- Saves model to `models/rnn_lstm/rnn_lstm_brain_tumor_classifier.pth`
- Saves all outputs (curves, confusion matrix, reports) to `models/rnn_lstm/`

### Model Comparison:

Both notebooks generate comprehensive reports that can be compared:
- Test accuracy
- Per-class metrics (precision, recall, F1-score)
- Confusion matrices
- Training curves

---

## 3ï¸âƒ£ Train VGG16 â€” Classification (Legacy)

**Note:** This section is for the original VGG16 training script. The CNN and RNN-LSTM notebooks are the recommended approach.

**Important:** Make sure you've run the preprocessing script first.

### Windows:
```cmd
python scripts/classify_vgg16.py --data_dir data/vgg16_classification --epochs 30 --batch_size 64 --learning_rate 1e-4 --model_save_path models/vgg16_classifier_best.pth
```

### Linux:
```bash
python scripts/classify_vgg16.py \
    --data_dir data/vgg16_classification \
    --epochs 30 \
    --batch_size 64 \
    --learning_rate 1e-4 \
    --model_save_path models/vgg16_classifier_best.pth
```

---

## 3ï¸âƒ£ Train RNN-GRU Model

The RNN-GRU notebook trains a hybrid CNN-GRU model that combines:
- **CNN layers** for spatial feature extraction
- **GRU layers** for sequential processing of features (faster and more efficient than LSTM)

**Important:** Make sure you've run the preprocessing script first. For best results, also run `augment_training_data.py` to create augmented training data.

### Windows & Linux:

**Using Conda (Recommended):**
```cmd
# Windows
conda activate deep-mric
jupyter notebook

# Linux
conda activate deep-mric
jupyter notebook
```

**Using pip/venv:**
```cmd
# Windows
venv\Scripts\activate
jupyter notebook

# Linux
source venv/bin/activate
jupyter notebook
```

Then:
1. **Open `train_gru.ipynb`** in the browser
2. **Run all cells** (Cell â†’ Run All)

### What the Notebook Does:

- Loads and preprocesses data (same as CNN and LSTM notebooks)
- Defines CNN-GRU hybrid architecture:
  - CNN feature extractor (3 convolutional blocks)
  - GRU layers to process CNN features as sequences
  - Fully connected layers for classification
- Trains the model with the same training pipeline as CNN and LSTM
- Generates the same evaluation metrics and visualizations
- Saves model to `models/gru/gru_brain_tumor_classifier.pth`
- Saves all outputs (curves, confusion matrix, reports) to `models/gru/`

### GRU vs LSTM Comparison:

- **GRU**: Faster training, fewer parameters, similar performance
- **LSTM**: May capture longer dependencies, slightly more parameters
- Both architectures are available for comparison

---

## 4ï¸âƒ£ Train K-Means Clustering Model

K-Means is an **unsupervised learning** algorithm that groups similar images together without requiring labeled data.

### Windows & Linux:

**Using Conda (Recommended):**
```cmd
# Windows
conda activate deep-mric
jupyter notebook

# Linux
conda activate deep-mric
jupyter notebook
```

**Using pip/venv:**
```cmd
# Windows
venv\Scripts\activate
jupyter notebook

# Linux
source venv/bin/activate
jupyter notebook
```

Then:
1. **Open `train_kmeans.ipynb`** in the browser
2. **Run all cells** (Cell â†’ Run All)

### What the Notebook Does:

- Loads images from `data/vgg16_classification/train/`
- Extracts features (flattens images, applies PCA for dimensionality reduction)
- Applies K-Means clustering with configurable number of clusters (default: 4)
- Evaluates clustering performance:
  - Silhouette Score
  - Adjusted Rand Index (compares clusters to true labels)
  - Inertia (within-cluster sum of squares)
- Generates visualizations:
  - Cluster-to-class mapping heatmap
  - Confusion matrix (mapping clusters to most common class)
  - Silhouette analysis
  - PCA 2D visualization
  - Cluster centers visualization
  - Sample images from each cluster
  - Elbow method for optimal K selection
- Saves model to `models/kmeans/kmeans_clusterer.pkl`
- Saves all outputs to `models/kmeans/`

**Note:** K-Means is unsupervised - it doesn't use class labels during training, but can compare cluster assignments with true labels for evaluation.

---

## 5ï¸âƒ£ Train YOLOv8 â€” Detection Model

YOLOv8 is used for tumor detection and localization with bounding boxes.

**Important:** Before training YOLOv8, you need to prepare the dataset:
```cmd
# Windows
python prepare_yolo_dataset.py

# Linux
python3 prepare_yolo_dataset.py
```

This creates the YOLOv8 dataset structure in `data/yolov8/`.

### Windows & Linux:

**Using Conda (Recommended):**
```cmd
# Windows
conda activate deep-mric
jupyter notebook

# Linux
conda activate deep-mric
jupyter notebook
```

**Using pip/venv:**
```cmd
# Windows
venv\Scripts\activate
jupyter notebook

# Linux
source venv/bin/activate
jupyter notebook
```

Then:
1. **Open `train_yolov8.ipynb`** in the browser
2. **Run all cells** (Cell â†’ Run All)

### What the Notebook Does:

- Checks YOLOv8 dataset structure
- Initializes YOLOv8 model (nano, small, medium, large, or xlarge)
- Trains the model with configurable hyperparameters:
  - Epochs (default: 50)
  - Batch size (default: 16)
  - Image size (default: 640x640)
  - Early stopping patience
- Evaluates on validation set:
  - mAP@0.5
  - mAP@0.5:0.95
  - Precision
  - Recall
- Tests on sample images with bounding box predictions
- Saves model to `models/yolov8/yolov8_tumor_detection/weights/best.pt`
- Saves all outputs (training plots, predictions) to `models/yolov8/`

**Note:** YOLOv8 requires bounding box annotations. The `prepare_yolo_dataset.py` script creates a basic structure, but for real detection, you may need to manually annotate images using tools like [LabelImg](https://github.com/tzutalin/labelImg).

---

# ğŸ” Inference / Testing

## Using Trained Models

After training, you can use the saved models for inference on new images. The training notebooks include evaluation on the test set, but you can also load the models for custom inference.

### Loading and Using Trained Models

**Example code (can be added to notebooks):**

```python
import torch
from PIL import Image
import torchvision.transforms as transforms

# Load trained CNN model
model = BrainTumorCNN(num_classes=4)
checkpoint = torch.load('models/cnn/cnn_brain_tumor_classifier.pth')
model.load_state_dict(checkpoint['model_state_dict'])
model.eval()

# Preprocess image
transform = transforms.Compose([
    transforms.Resize((224, 224)),
    transforms.ToTensor(),
    transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225])
])

# Load and predict
image = Image.open('path/to/image.jpg')
image_tensor = transform(image).unsqueeze(0)
with torch.no_grad():
    output = model(image_tensor)
    probabilities = torch.nn.functional.softmax(output, dim=1)
    predicted_class = torch.argmax(probabilities, dim=1).item()
    confidence = probabilities[0][predicted_class].item()

print(f"Predicted: {CLASS_NAMES[predicted_class]} ({confidence*100:.2f}% confidence)")
```

---

## YOLOv8 Detection (Optional)

### Windows:
```cmd
yolo task=detect mode=predict model=runs/detect/yolov8_tumor_detection/weights/best.pt source=data/test_images/sample_mri.png conf=0.25
```

### Linux:
```bash
yolo task=detect mode=predict \
    model=runs/detect/yolov8_tumor_detection/weights/best.pt \
    source=data/test_images/sample_mri.png \
    conf=0.25
```

Output saved in:
```
runs/detect/predict/
```

---

# ğŸ“Š Evaluation

## Model Evaluation Metrics

CNN, RNN-LSTM, and RNN-GRU notebooks automatically generate comprehensive evaluation metrics:

### Classification Metrics:
- **Accuracy**: Overall classification accuracy (calculated using `sklearn.metrics.accuracy_score`)
- **Precision**: Per-class and macro/micro averages
- **Recall**: Per-class and macro/micro averages
- **F1-Score**: Per-class and macro/micro averages
- **Confusion Matrix**: Visual heatmap showing classification performance (generated using `sklearn.metrics.confusion_matrix` and visualized with `seaborn.heatmap`)
- **Classification Report**: Detailed per-class metrics saved to text file (generated using `sklearn.metrics.classification_report`)

### Visualizations Generated:
- **Training Curves**: Loss and accuracy plots for training and validation
- **Confusion Matrix**: Heatmap visualization saved as PNG
- **Sample Predictions**: 10 sample test images with predictions and confidence scores

### Output Files:

After training, the following files are saved in the `models/` directory:

**CNN Model:**
- `cnn_brain_tumor_classifier.pth` - Trained model checkpoint
- `cnn_training_history.csv` - Training history (loss, accuracy per epoch)
- `cnn_training_curves.png` - Training/validation curves
- `cnn_confusion_matrix.png` - Confusion matrix visualization
- `cnn_classification_report.txt` - Detailed classification report
- `cnn_sample_predictions.png` - Sample predictions visualization

**RNN-LSTM Model:**
- `rnn_lstm_brain_tumor_classifier.pth` - Trained model checkpoint
- `rnn_lstm_training_history.csv` - Training history
- `rnn_lstm_training_curves.png` - Training/validation curves
- `rnn_lstm_confusion_matrix.png` - Confusion matrix visualization
- `rnn_lstm_classification_report.txt` - Detailed classification report
- `rnn_lstm_sample_predictions.png` - Sample predictions visualization

**RNN-GRU Model:**
- `gru_brain_tumor_classifier.pth` - Trained model checkpoint
- `gru_training_history.csv` - Training history
- `gru_training_curves.png` - Training/validation curves
- `gru_confusion_matrix.png` - Confusion matrix visualization
- `gru_classification_report.txt` - Detailed classification report
- `gru_sample_predictions.png` - Sample predictions visualization

### Comparing Models:

To compare CNN, RNN-LSTM, and RNN-GRU performance:
1. Train all models using their respective notebooks
2. Check the test accuracy printed in each notebook
3. Compare confusion matrices (saved as PNG files)
4. Review classification reports (saved as text files)
5. Compare training curves to see convergence behavior
6. Consider training time: CNN < GRU < LSTM (GRU is faster than LSTM with similar performance)

## YOLOv8 Metrics (Optional)

For YOLOv8 detection model:
* mAP@0.5
* mAP@0.5:0.95
* IoU
* Precision-Recall curves

### Run YOLO evaluation:

**Windows:**
```cmd
yolo mode=val model=runs/detect/yolov8_tumor_detection/weights/best.pt data=tumor_data.yaml
```

**Linux:**
```bash
yolo mode=val model=runs/detect/yolov8_tumor_detection/weights/best.pt data=tumor_data.yaml
```

---

# ğŸ›  Requirements

All dependencies are listed in `requirements.txt` and `environment.yml`. The main packages include:

## Core Dependencies
- **opencv-python** (â‰¥4.5.0) - Image processing and computer vision
- **pillow** (â‰¥9.0.0) - Image loading and manipulation (used in data augmentation)
- **numpy** (â‰¥1.21.0) - Numerical computing
- **scikit-learn** (â‰¥1.0.0) - Machine learning utilities (train/test split, evaluation metrics: accuracy_score, classification_report, confusion_matrix)
- **tqdm** (â‰¥4.62.0) - Progress bars

## Deep Learning (for training)
- **torch** (â‰¥1.12.0) - PyTorch framework for deep learning
- **torchvision** (â‰¥0.13.0) - PyTorch vision utilities and datasets (used for data augmentation transforms)
- **pandas** (â‰¥1.3.0) - Data manipulation and analysis
- **seaborn** (â‰¥0.12.0) - Statistical data visualization (for confusion matrix heatmaps and evaluation visualizations)
- **ultralytics** - YOLOv8 implementation (optional, for detection)

## Jupyter Notebook Support
- **jupyter** (â‰¥1.0.0) - Jupyter notebook environment
- **ipykernel** (â‰¥6.0.0) - Jupyter kernel
- **matplotlib** (â‰¥3.5.0) - Plotting and visualization
- **ipywidgets** (â‰¥7.6.0) - Interactive widgets

## Installation

Install all requirements using one of the methods in the [Installation](#2ï¸âƒ£-installation) section above.

**Quick install:**
```bash
pip install -r requirements.txt
```

Or with conda:
```bash
conda env create -f environment.yml
```

---

# ğŸ§ª Results

## Model Performance

After training, you can compare the performance of different models:

| Model      | Architecture | Task           | Output Files                      |
| ---------- | ------------ | -------------- | --------------------------------- |
| **CNN**    | Custom CNN   | Classification | `models/cnn_*` files              |
| **RNN-LSTM** | CNN-LSTM Hybrid | Classification | `models/rnn_lstm_*` files         |
| **RNN-GRU** | CNN-GRU Hybrid | Classification | `models/gru_*` files              |
| **K-Means** | Unsupervised Clustering | Clustering | `models/kmeans_*` files           |
| **YOLOv8** | Object Detection | Detection      | `models/yolov8/` directory        |

### Typical Performance Metrics:

- **Accuracy**: CNN, RNN-LSTM, and RNN-GRU models typically achieve high accuracy (>85%)
- **Per-Class Metrics**: Detailed precision, recall, and F1-score for each tumor type
- **Training Time**: CNN < RNN-GRU < RNN-LSTM (GRU is faster than LSTM)
- **Model Size**: CNN models are generally smaller than RNN-based models
- **Augmented Data**: Using augmented training data (6x larger) typically improves model generalization and accuracy

### Reporting:

All generated files (confusion matrices, classification reports, training curves) can be directly used in research reports and presentations.

---


# ğŸ“œ License

This project is free for research and educational use.

---

# ğŸ› Troubleshooting

## Common Issues

### Issue: `ModuleNotFoundError` when running scripts
**Solution:** Make sure your virtual environment is activated and all dependencies are installed:
```bash
# Activate venv
# Windows: venv\Scripts\activate
# Linux: source venv/bin/activate

# Reinstall requirements
pip install -r requirements.txt
```

### Issue: OpenCV installation fails
**Solution:** Try installing with conda instead:
```bash
conda install -c conda-forge opencv
```

### Issue: Preprocessing script can't find images
**Solution:** 
- Check that your raw data is in `data/raw_dataset/` with class subfolders
- Verify image file extensions are `.jpg`, `.jpeg`, or `.png`
- Check file permissions (especially on Linux)

### Issue: Jupyter notebook not starting
**Solution:** 
- Install Jupyter: `pip install jupyter ipykernel`
- Or use conda: `conda install jupyter ipykernel`
- Start with: `jupyter notebook`

### Issue: CUDA/GPU not detected (for training)
**Solution:**
- Install PyTorch with CUDA support: Visit [pytorch.org](https://pytorch.org) for installation instructions
- **Windows**: Verify GPU: `python -c "import torch; print(torch.cuda.is_available())"`
- **Linux**: Verify GPU: `python3 -c "import torch; print(torch.cuda.is_available())"`
- If CUDA is not available, training will automatically use CPU (slower but functional)

### Issue: Jupyter notebook kernel not found
**Solution:**
- **Windows**: `python -m ipykernel install --user --name=deep-mric`
- **Linux**: `python3 -m ipykernel install --user --name=deep-mric`
- Restart Jupyter notebook and select the kernel

### Issue: Out of memory during training
**Solution:**
- Reduce `BATCH_SIZE` in the notebook configuration (try 16 or 8)
- Close other applications to free up GPU/CPU memory
- Use CPU training if GPU memory is insufficient (slower but works)

### Issue: Training is very slow
**Solution:**
- Ensure CUDA is properly installed and GPU is being used
- Check GPU utilization: `nvidia-smi` (Linux) or Task Manager â†’ Performance (Windows)
- Reduce batch size if memory constrained
- Consider using a smaller model architecture

---

# â­ Support

If this project helps you, please **â­ star the repo** on GitHub!

For issues, questions, or contributions, please open an issue on GitHub.


