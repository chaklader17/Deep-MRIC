{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# RNN with GRU Model Training for Brain Tumor Classification\n",
    "\n",
    "This notebook trains a hybrid CNN-GRU model to classify brain MRI images into 4 categories:\n",
    "- **NO_TUMOR**: Healthy brain (no tumor detected)\n",
    "- **GLIOMA**: Glioma tumor type\n",
    "- **MENINGIOMA**: Meningioma tumor type\n",
    "- **PITUITARY**: Pituitary tumor type\n",
    "\n",
    "## Overview\n",
    "\n",
    "This notebook implements a **CNN-GRU hybrid architecture**:\n",
    "1. **CNN Feature Extractor**: Extracts spatial features from images using convolutional layers\n",
    "2. **GRU Layers**: Processes the extracted features as sequences (GRU is faster and more efficient than LSTM)\n",
    "3. **Fully Connected Layers**: Final classification into 4 classes\n",
    "\n",
    "This approach combines the spatial feature extraction capabilities of CNNs with the sequential modeling power of GRUs.\n",
    "\n",
    "## Requirements\n",
    "\n",
    "Make sure you have installed all required packages:\n",
    "```bash\n",
    "pip install torch torchvision seaborn pandas scikit-learn matplotlib numpy tqdm\n",
    "```\n",
    "\n",
    "Or install from requirements.txt:\n",
    "```bash\n",
    "pip install -r requirements.txt\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Setup and Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torch.utils.data import DataLoader\n",
    "import torchvision.transforms as transforms\n",
    "from torchvision.datasets import ImageFolder\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from sklearn.metrics import confusion_matrix, classification_report, accuracy_score\n",
    "from tqdm import tqdm\n",
    "import os\n",
    "import random\n",
    "from pathlib import Path\n",
    "\n",
    "# Set random seeds for reproducibility\n",
    "def set_seed(seed=42):\n",
    "    random.seed(seed)\n",
    "    np.random.seed(seed)\n",
    "    torch.manual_seed(seed)\n",
    "    torch.cuda.manual_seed_all(seed)\n",
    "    torch.backends.cudnn.deterministic = True\n",
    "    torch.backends.cudnn.benchmark = False\n",
    "\n",
    "set_seed(42)\n",
    "\n",
    "# Set device\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "print(f'Using device: {device}')\n",
    "if torch.cuda.is_available():\n",
    "    print(f'GPU: {torch.cuda.get_device_name(0)}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Configuration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Configuration\n",
    "DATA_DIR = 'data/vgg16_classification'\n",
    "MODEL_DIR = 'models/gru'\n",
    "MODEL_SAVE_PATH = os.path.join(MODEL_DIR, 'gru_brain_tumor_classifier.pth')\n",
    "HISTORY_SAVE_PATH = os.path.join(MODEL_DIR, 'gru_training_history.csv')\n",
    "\n",
    "# Training hyperparameters\n",
    "BATCH_SIZE = 32\n",
    "LEARNING_RATE = 0.001\n",
    "NUM_EPOCHS = 50\n",
    "NUM_CLASSES = 4\n",
    "\n",
    "# Class names\n",
    "CLASS_NAMES = ['NO_TUMOR', 'GLIOMA', 'MENINGIOMA', 'PITUITARY']\n",
    "\n",
    "# Create models directory if it doesn't exist\n",
    "os.makedirs(MODEL_DIR, exist_ok=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## 3. Custom Dataset Class Using CSV Metadata\n",
    "\n",
    "# Custom dataset class that uses CSV metadata to prevent data leakage\n",
    "from torch.utils.data import Dataset\n",
    "from PIL import Image\n",
    "\n",
    "class FilteredImageFolder(Dataset):\n",
    "    \"\"\"\n",
    "    Custom dataset that loads images based on CSV metadata to prevent data leakage.\n",
    "    Only loads images whose original_filename is NOT in other splits.\n",
    "    \"\"\"\n",
    "    def __init__(self, metadata_df, split_name, transform=None, base_dir='data/vgg16_classification'):\n",
    "        \"\"\"\n",
    "        Args:\n",
    "            metadata_df: DataFrame with columns: image_path, full_path, class, split, filename, original_filename (optional)\n",
    "            split_name: 'train', 'val', or 'test'\n",
    "            transform: Image transforms\n",
    "            base_dir: Base directory for images\n",
    "        \"\"\"\n",
    "        self.split_name = split_name\n",
    "        self.transform = transform\n",
    "        self.base_dir = base_dir\n",
    "        \n",
    "        # Filter by split\n",
    "        split_df = metadata_df[metadata_df['split'] == split_name].copy()\n",
    "        \n",
    "        # For train: use augmented metadata, filter by original_filename not in test/val\n",
    "        if split_name == 'train':\n",
    "            # Get original filenames from test and val splits (from original metadata)\n",
    "            if 'original_filename' in metadata_df.columns:\n",
    "                # This is augmented metadata\n",
    "                orig_metadata_path = 'data/dataset_metadata.csv'\n",
    "                if os.path.exists(orig_metadata_path):\n",
    "                    orig_df = pd.read_csv(orig_metadata_path)\n",
    "                    test_originals = set(orig_df[orig_df['split'] == 'test']['filename'].unique())\n",
    "                    val_originals = set(orig_df[orig_df['split'] == 'val']['filename'].unique())\n",
    "                    excluded_originals = test_originals.union(val_originals)\n",
    "                    # Filter: only keep images whose original_filename is NOT in test/val\n",
    "                    split_df = split_df[~split_df['original_filename'].isin(excluded_originals)]\n",
    "        \n",
    "        # For val/test: use original metadata, ensure no overlap with train\n",
    "        elif split_name in ['val', 'test']:\n",
    "            # Get train original filenames (from augmented metadata if available)\n",
    "            aug_metadata_path = 'data/augmented_dataset_metadata.csv'\n",
    "            if os.path.exists(aug_metadata_path):\n",
    "                aug_df = pd.read_csv(aug_metadata_path)\n",
    "                train_originals = set(aug_df[aug_df['split'] == 'train']['original_filename'].unique())\n",
    "                # Filter: only keep images whose filename is NOT in train\n",
    "                split_df = split_df[~split_df['filename'].isin(train_originals)]\n",
    "        \n",
    "        self.samples = []\n",
    "        self.classes = sorted(split_df['class'].unique().tolist())\n",
    "        self.class_to_idx = {cls_name: idx for idx, cls_name in enumerate(self.classes)}\n",
    "        \n",
    "        for _, row in split_df.iterrows():\n",
    "            # Use full_path if available, otherwise construct from base_dir and image_path\n",
    "            if pd.notna(row.get('full_path')):\n",
    "                img_path = row['full_path']\n",
    "            else:\n",
    "                img_path = os.path.join(base_dir, row['image_path'])\n",
    "            \n",
    "            # Normalize path separators\n",
    "            img_path = img_path.replace('\\\\', '/')\n",
    "            \n",
    "            if os.path.exists(img_path):\n",
    "                label = self.class_to_idx[row['class']]\n",
    "                self.samples.append((img_path, label))\n",
    "            else:\n",
    "                print(f\"Warning: Image not found: {img_path}\")\n",
    "        \n",
    "        print(f\"Loaded {len(self.samples)} images for {split_name} split (filtered from {len(split_df)} rows in CSV)\")\n",
    "    \n",
    "    def __len__(self):\n",
    "        return len(self.samples)\n",
    "    \n",
    "    def __getitem__(self, idx):\n",
    "        img_path, label = self.samples[idx]\n",
    "        \n",
    "        try:\n",
    "            image = Image.open(img_path).convert('RGB')\n",
    "        except Exception as e:\n",
    "            print(f\"Error loading {img_path}: {e}\")\n",
    "            # Return a black image as fallback\n",
    "            image = Image.new('RGB', (224, 224), (0, 0, 0))\n",
    "        \n",
    "        if self.transform:\n",
    "            image = self.transform(image)\n",
    "        \n",
    "        return image, label\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Data Loading and Preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Data transforms\n",
    "# Training: only normalization (augmentation already applied via augment_training_data.py)\n",
    "# Use train_augmented directory which contains pre-augmented images\n",
    "train_transform = transforms.Compose([\n",
    "    transforms.Resize((224, 224)),\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225])\n",
    "])\n",
    "\n",
    "# Validation/Test: only normalization (no augmentation)\n",
    "val_test_transform = transforms.Compose([\n",
    "    transforms.Resize((224, 224)),\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225])\n",
    "])\n",
    "\n",
    "# Load datasets using CSV metadata to prevent data leakage\n",
    "# #region agent log\n",
    "import json\n",
    "import time\n",
    "LOG_PATH = '/home/benaaf/CSE465/Deep-MRIC/.cursor/debug.log'\n",
    "def log_debug(location, message, data, hypothesis_id='A'):\n",
    "    try:\n",
    "        os.makedirs(os.path.dirname(LOG_PATH), exist_ok=True)\n",
    "        with open(LOG_PATH, 'a') as f:\n",
    "            log_entry = {\n",
    "                'id': f'log_{int(time.time()*1000)}',\n",
    "                'timestamp': int(time.time()*1000),\n",
    "                'location': location,\n",
    "                'message': message,\n",
    "                'data': data,\n",
    "                'sessionId': 'debug-session',\n",
    "                'runId': 'post-fix',\n",
    "                'hypothesisId': hypothesis_id\n",
    "            }\n",
    "            f.write(json.dumps(log_entry) + '\\n')\n",
    "    except Exception as e:\n",
    "        print(f\"Logging error: {e}\")\n",
    "# #endregion\n",
    "print(\"Loading datasets using CSV metadata files to prevent data leakage...\")\n",
    "\n",
    "# Load metadata CSV files\n",
    "augmented_metadata_path = 'data/augmented_dataset_metadata.csv'\n",
    "original_metadata_path = 'data/dataset_metadata.csv'\n",
    "\n",
    "if os.path.exists(augmented_metadata_path):\n",
    "    aug_metadata_df = pd.read_csv(augmented_metadata_path)\n",
    "    print(f\"Loaded augmented metadata: {len(aug_metadata_df)} rows\")\n",
    "else:\n",
    "    print(f\"Warning: {augmented_metadata_path} not found. Creating empty DataFrame.\")\n",
    "    aug_metadata_df = pd.DataFrame()\n",
    "\n",
    "if os.path.exists(original_metadata_path):\n",
    "    orig_metadata_df = pd.read_csv(original_metadata_path)\n",
    "    print(f\"Loaded original metadata: {len(orig_metadata_df)} rows\")\n",
    "else:\n",
    "    print(f\"Warning: {original_metadata_path} not found. Creating empty DataFrame.\")\n",
    "    orig_metadata_df = pd.DataFrame()\n",
    "\n",
    "# Use FilteredImageFolder for train (from augmented metadata)\n",
    "if len(aug_metadata_df) > 0:\n",
    "    train_dataset = FilteredImageFolder(aug_metadata_df, 'train', transform=train_transform, base_dir=DATA_DIR)\n",
    "else:\n",
    "    print(\"Falling back to ImageFolder for train (no augmented metadata found)\")\n",
    "    train_dir = os.path.join(DATA_DIR, 'train_augmented')\n",
    "    if not os.path.exists(train_dir):\n",
    "        train_dir = os.path.join(DATA_DIR, 'train')\n",
    "    train_dataset = ImageFolder(root=train_dir, transform=train_transform)\n",
    "\n",
    "# Use FilteredImageFolder for val and test (from original metadata)\n",
    "if len(orig_metadata_df) > 0:\n",
    "    val_dataset = FilteredImageFolder(orig_metadata_df, 'val', transform=val_test_transform, base_dir=DATA_DIR)\n",
    "    test_dataset = FilteredImageFolder(orig_metadata_df, 'test', transform=val_test_transform, base_dir=DATA_DIR)\n",
    "else:\n",
    "    print(\"Falling back to ImageFolder for val/test (no original metadata found)\")\n",
    "    val_dataset = ImageFolder(root=os.path.join(DATA_DIR, 'val'), transform=val_test_transform)\n",
    "    test_dataset = ImageFolder(root=os.path.join(DATA_DIR, 'test'), transform=val_test_transform)\n",
    "\n",
    "# #region agent log\n",
    "# Verify no data leakage after filtering\n",
    "def extract_original_filenames_from_dataset(dataset, split_name):\n",
    "    \"\"\"Extract original filenames from dataset samples\"\"\"\n",
    "    original_filenames = set()\n",
    "    for path, _ in dataset.samples:\n",
    "        filename = os.path.basename(path)\n",
    "        if '_aug' in filename:\n",
    "            parts = filename.split('_aug')\n",
    "            if len(parts) > 1:\n",
    "                base = parts[0]\n",
    "                ext = os.path.splitext(filename)[1]\n",
    "                original_filename = base + ext\n",
    "            else:\n",
    "                original_filename = filename\n",
    "        else:\n",
    "            original_filename = filename\n",
    "        original_filenames.add(original_filename)\n",
    "    return original_filenames\n",
    "\n",
    "train_originals = extract_original_filenames_from_dataset(train_dataset, 'train')\n",
    "val_originals = extract_original_filenames_from_dataset(val_dataset, 'val')\n",
    "test_originals = extract_original_filenames_from_dataset(test_dataset, 'test')\n",
    "\n",
    "train_test_overlap = train_originals.intersection(test_originals)\n",
    "train_val_overlap = train_originals.intersection(val_originals)\n",
    "val_test_overlap = val_originals.intersection(test_originals)\n",
    "\n",
    "log_debug('train_gru.ipynb:7', 'Post-fix data leakage check', {\n",
    "    'train_unique_originals': len(train_originals),\n",
    "    'val_unique_originals': len(val_originals),\n",
    "    'test_unique_originals': len(test_originals),\n",
    "    'train_test_overlap_count': len(train_test_overlap),\n",
    "    'train_val_overlap_count': len(train_val_overlap),\n",
    "    'val_test_overlap_count': len(val_test_overlap),\n",
    "    'has_data_leakage': len(train_test_overlap) > 0,\n",
    "    'using_csv_metadata': True,\n",
    "    'train_samples': len(train_dataset),\n",
    "    'val_samples': len(val_dataset),\n",
    "    'test_samples': len(test_dataset)\n",
    "}, 'B')\n",
    "# #endregion\n",
    "\n",
    "# Create data loaders\n",
    "train_loader = DataLoader(train_dataset, batch_size=BATCH_SIZE, shuffle=True, num_workers=2)\n",
    "val_loader = DataLoader(val_dataset, batch_size=BATCH_SIZE, shuffle=False, num_workers=2)\n",
    "test_loader = DataLoader(test_dataset, batch_size=BATCH_SIZE, shuffle=False, num_workers=2)\n",
    "\n",
    "print(f'\\nTrain samples: {len(train_dataset)}')\n",
    "print(f'Validation samples: {len(val_dataset)}')\n",
    "print(f'Test samples: {len(test_dataset)}')\n",
    "print(f'Number of classes: {len(train_dataset.classes)}')\n",
    "print(f'Class names: {train_dataset.classes}')\n",
    "\n",
    "if train_test_overlap:\n",
    "    print(f'\\n  WARNING: Still found {len(train_test_overlap)} overlapping files between train and test!')\n",
    "else:\n",
    "    print(f'\\n SUCCESS: No data leakage detected! Train and test sets are properly separated.')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.1 Class Distribution"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Display class distribution\n",
    "def get_class_distribution(dataset):\n",
    "    class_counts = {}\n",
    "    for _, label in dataset:\n",
    "        class_name = dataset.classes[label]\n",
    "        class_counts[class_name] = class_counts.get(class_name, 0) + 1\n",
    "    return class_counts\n",
    "\n",
    "train_dist = get_class_distribution(train_dataset)\n",
    "val_dist = get_class_distribution(val_dataset)\n",
    "test_dist = get_class_distribution(test_dataset)\n",
    "\n",
    "# Create visualization\n",
    "fig, axes = plt.subplots(1, 3, figsize=(18, 5))\n",
    "\n",
    "for idx, (dist, title) in enumerate([(train_dist, 'Train'), (val_dist, 'Validation'), (test_dist, 'Test')]):\n",
    "    classes = list(dist.keys())\n",
    "    counts = list(dist.values())\n",
    "    axes[idx].bar(classes, counts, color=['#1f77b4', '#ff7f0e', '#2ca02c', '#d62728'])\n",
    "    axes[idx].set_title(f'{title} Set Class Distribution', fontsize=14, fontweight='bold')\n",
    "    axes[idx].set_xlabel('Class', fontsize=12)\n",
    "    axes[idx].set_ylabel('Number of Samples', fontsize=12)\n",
    "    axes[idx].tick_params(axis='x', rotation=45)\n",
    "    for i, v in enumerate(counts):\n",
    "        axes[idx].text(i, v, str(v), ha='center', va='bottom')\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "# Print summary\n",
    "print(\"\\nClass Distribution Summary:\")\n",
    "print(f\"{'Class':<15} {'Train':<10} {'Val':<10} {'Test':<10}\")\n",
    "print(\"-\" * 50)\n",
    "for class_name in CLASS_NAMES:\n",
    "    print(f\"{class_name:<15} {train_dist.get(class_name, 0):<10} {val_dist.get(class_name, 0):<10} {test_dist.get(class_name, 0):<10}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. CNN-GRU Model Architecture"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class BrainTumorCNNGRU(nn.Module):\n",
    "    def __init__(self, num_classes=4):\n",
    "        super(BrainTumorCNNGRU, self).__init__()\n",
    "        \n",
    "        # CNN Feature Extractor\n",
    "        self.conv1 = nn.Sequential(\n",
    "            nn.Conv2d(3, 32, kernel_size=3, padding=1),\n",
    "            nn.BatchNorm2d(32),\n",
    "            nn.ReLU(inplace=True),\n",
    "            nn.Conv2d(32, 32, kernel_size=3, padding=1),\n",
    "            nn.BatchNorm2d(32),\n",
    "            nn.ReLU(inplace=True),\n",
    "            nn.MaxPool2d(kernel_size=2, stride=2)\n",
    "        )\n",
    "        \n",
    "        self.conv2 = nn.Sequential(\n",
    "            nn.Conv2d(32, 64, kernel_size=3, padding=1),\n",
    "            nn.BatchNorm2d(64),\n",
    "            nn.ReLU(inplace=True),\n",
    "            nn.Conv2d(64, 64, kernel_size=3, padding=1),\n",
    "            nn.BatchNorm2d(64),\n",
    "            nn.ReLU(inplace=True),\n",
    "            nn.MaxPool2d(kernel_size=2, stride=2)\n",
    "        )\n",
    "        \n",
    "        self.conv3 = nn.Sequential(\n",
    "            nn.Conv2d(64, 128, kernel_size=3, padding=1),\n",
    "            nn.BatchNorm2d(128),\n",
    "            nn.ReLU(inplace=True),\n",
    "            nn.Conv2d(128, 128, kernel_size=3, padding=1),\n",
    "            nn.BatchNorm2d(128),\n",
    "            nn.ReLU(inplace=True),\n",
    "            nn.MaxPool2d(kernel_size=2, stride=2)\n",
    "        )\n",
    "        \n",
    "        # Adaptive pooling to get fixed size feature maps\n",
    "        self.adaptive_pool = nn.AdaptiveAvgPool2d((7, 7))\n",
    "        \n",
    "        # Flatten spatial dimensions for GRU\n",
    "        # After pooling: 128 channels * 7 * 7 = 6272 features\n",
    "        self.feature_size = 128 * 7 * 7\n",
    "        \n",
    "        # GRU layers (GRU is faster and more efficient than LSTM)\n",
    "        self.gru = nn.GRU(input_size=self.feature_size, hidden_size=256, \n",
    "                         num_layers=2, batch_first=True, dropout=0.3)\n",
    "        \n",
    "        # Fully connected layers\n",
    "        self.fc = nn.Sequential(\n",
    "            nn.Dropout(0.5),\n",
    "            nn.Linear(256, 128),\n",
    "            nn.ReLU(inplace=True),\n",
    "            nn.Dropout(0.5),\n",
    "            nn.Linear(128, num_classes)\n",
    "        )\n",
    "        \n",
    "    def forward(self, x):\n",
    "        # CNN feature extraction\n",
    "        x = self.conv1(x)\n",
    "        x = self.conv2(x)\n",
    "        x = self.conv3(x)\n",
    "        x = self.adaptive_pool(x)\n",
    "        \n",
    "        # Reshape for GRU: (batch, channels, height, width) -> (batch, seq_len, features)\n",
    "        batch_size = x.size(0)\n",
    "        x = x.view(batch_size, -1, self.feature_size)  # (batch, 1, feature_size)\n",
    "        \n",
    "        # GRU processing\n",
    "        gru_out, h_n = self.gru(x)\n",
    "        # Use the last output\n",
    "        gru_out = gru_out[:, -1, :]  # (batch, hidden_size)\n",
    "        \n",
    "        # Classification\n",
    "        x = self.fc(gru_out)\n",
    "        return x\n",
    "\n",
    "# Initialize model\n",
    "model = BrainTumorCNNGRU(num_classes=NUM_CLASSES).to(device)\n",
    "\n",
    "# Print model architecture\n",
    "print(\"CNN-GRU Model Architecture:\")\n",
    "print(model)\n",
    "\n",
    "# Count parameters\n",
    "total_params = sum(p.numel() for p in model.parameters())\n",
    "trainable_params = sum(p.numel() for p in model.parameters() if p.requires_grad)\n",
    "print(f\"\\nTotal parameters: {total_params:,}\")\n",
    "print(f\"Trainable parameters: {trainable_params:,}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5. Training Configuration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Loss function\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "\n",
    "# Optimizer\n",
    "optimizer = optim.Adam(model.parameters(), lr=LEARNING_RATE, weight_decay=1e-5)\n",
    "\n",
    "# Learning rate scheduler\n",
    "scheduler = optim.lr_scheduler.ReduceLROnPlateau(optimizer, mode='min', factor=0.5, patience=5)\n",
    "\n",
    "print(f\"Loss function: CrossEntropyLoss\")\n",
    "print(f\"Optimizer: Adam (lr={LEARNING_RATE})\")\n",
    "print(f\"Learning rate scheduler: ReduceLROnPlateau\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 6. Training Loop"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_epoch(model, loader, criterion, optimizer, device):\n",
    "    model.train()\n",
    "    running_loss = 0.0\n",
    "    correct = 0\n",
    "    total = 0\n",
    "    \n",
    "    for images, labels in tqdm(loader, desc='Training'):\n",
    "        images, labels = images.to(device), labels.to(device)\n",
    "        \n",
    "        # Forward pass\n",
    "        optimizer.zero_grad()\n",
    "        outputs = model(images)\n",
    "        loss = criterion(outputs, labels)\n",
    "        \n",
    "        # Backward pass\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        \n",
    "        # Statistics\n",
    "        running_loss += loss.item()\n",
    "        _, predicted = torch.max(outputs.data, 1)\n",
    "        total += labels.size(0)\n",
    "        correct += (predicted == labels).sum().item()\n",
    "    \n",
    "    epoch_loss = running_loss / len(loader)\n",
    "    epoch_acc = 100 * correct / total\n",
    "    return epoch_loss, epoch_acc\n",
    "\n",
    "def validate_epoch(model, loader, criterion, device):\n",
    "    model.eval()\n",
    "    running_loss = 0.0\n",
    "    correct = 0\n",
    "    total = 0\n",
    "    \n",
    "    with torch.no_grad():\n",
    "        for images, labels in tqdm(loader, desc='Validating'):\n",
    "            images, labels = images.to(device), labels.to(device)\n",
    "            \n",
    "            outputs = model(images)\n",
    "            loss = criterion(outputs, labels)\n",
    "            \n",
    "            running_loss += loss.item()\n",
    "            _, predicted = torch.max(outputs.data, 1)\n",
    "            total += labels.size(0)\n",
    "            correct += (predicted == labels).sum().item()\n",
    "    \n",
    "    epoch_loss = running_loss / len(loader)\n",
    "    epoch_acc = 100 * correct / total\n",
    "    return epoch_loss, epoch_acc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Training history\n",
    "history = {\n",
    "    'train_loss': [],\n",
    "    'train_acc': [],\n",
    "    'val_loss': [],\n",
    "    'val_acc': []\n",
    "}\n",
    "\n",
    "best_val_acc = 0.0\n",
    "patience_counter = 0\n",
    "early_stopping_patience = 10\n",
    "\n",
    "print(\"Starting training...\")\n",
    "print(f\"Training for {NUM_EPOCHS} epochs\")\n",
    "print(\"-\" * 60)\n",
    "\n",
    "for epoch in range(NUM_EPOCHS):\n",
    "    print(f\"\\nEpoch {epoch+1}/{NUM_EPOCHS}\")\n",
    "    \n",
    "    # Train\n",
    "    train_loss, train_acc = train_epoch(model, train_loader, criterion, optimizer, device)\n",
    "    \n",
    "    # Validate\n",
    "    val_loss, val_acc = validate_epoch(model, val_loader, criterion, device)\n",
    "    \n",
    "    # Update learning rate\n",
    "    scheduler.step(val_loss)\n",
    "    \n",
    "    # Save history\n",
    "    history['train_loss'].append(train_loss)\n",
    "    history['train_acc'].append(train_acc)\n",
    "    history['val_loss'].append(val_loss)\n",
    "    history['val_acc'].append(val_acc)\n",
    "    \n",
    "    # Print epoch results\n",
    "    print(f\"Train Loss: {train_loss:.4f}, Train Acc: {train_acc:.2f}%\")\n",
    "    print(f\"Val Loss: {val_loss:.4f}, Val Acc: {val_acc:.2f}%\")\n",
    "    print(f\"Learning Rate: {optimizer.param_groups[0]['lr']:.6f}\")\n",
    "    \n",
    "    # Save best model\n",
    "    if val_acc > best_val_acc:\n",
    "        best_val_acc = val_acc\n",
    "        torch.save({\n",
    "            'epoch': epoch + 1,\n",
    "            'model_state_dict': model.state_dict(),\n",
    "            'optimizer_state_dict': optimizer.state_dict(),\n",
    "            'val_acc': val_acc,\n",
    "            'history': history\n",
    "        }, MODEL_SAVE_PATH)\n",
    "        print(f\"Saved best model (Val Acc: {val_acc:.2f}%)\")\n",
    "        patience_counter = 0\n",
    "    else:\n",
    "        patience_counter += 1\n",
    "    \n",
    "    # Early stopping\n",
    "    if patience_counter >= early_stopping_patience:\n",
    "        print(f\"\\nEarly stopping triggered after {epoch+1} epochs\")\n",
    "        break\n",
    "\n",
    "print(\"\\n\" + \"=\" * 60)\n",
    "print(\"Training completed!\")\n",
    "print(f\"Best validation accuracy: {best_val_acc:.2f}%\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 6.1 Save Training History"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save training history to CSV\n",
    "history_df = pd.DataFrame(history)\n",
    "history_df.to_csv(HISTORY_SAVE_PATH, index=False)\n",
    "print(f\"Training history saved to {HISTORY_SAVE_PATH}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 7. Training Curves Visualization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot training curves\n",
    "fig, axes = plt.subplots(1, 2, figsize=(15, 5))\n",
    "\n",
    "# Loss curve\n",
    "axes[0].plot(history['train_loss'], label='Train Loss', linewidth=2)\n",
    "axes[0].plot(history['val_loss'], label='Validation Loss', linewidth=2)\n",
    "axes[0].set_xlabel('Epoch', fontsize=12)\n",
    "axes[0].set_ylabel('Loss', fontsize=12)\n",
    "axes[0].set_title('Training and Validation Loss', fontsize=14, fontweight='bold')\n",
    "axes[0].legend()\n",
    "axes[0].grid(True, alpha=0.3)\n",
    "\n",
    "# Accuracy curve\n",
    "axes[1].plot(history['train_acc'], label='Train Accuracy', linewidth=2)\n",
    "axes[1].plot(history['val_acc'], label='Validation Accuracy', linewidth=2)\n",
    "axes[1].set_xlabel('Epoch', fontsize=12)\n",
    "axes[1].set_ylabel('Accuracy (%)', fontsize=12)\n",
    "axes[1].set_title('Training and Validation Accuracy', fontsize=14, fontweight='bold')\n",
    "axes[1].legend()\n",
    "axes[1].grid(True, alpha=0.3)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.savefig(os.path.join(MODEL_DIR, 'gru_training_curves.png'), dpi=300, bbox_inches='tight')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 8. Load Best Model and Evaluate on Test Set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load best model\n",
    "checkpoint = torch.load(MODEL_SAVE_PATH)\n",
    "model.load_state_dict(checkpoint['model_state_dict'])\n",
    "print(f\"Loaded best model from epoch {checkpoint['epoch']}\")\n",
    "print(f\"Best validation accuracy: {checkpoint['val_acc']:.2f}%\")\n",
    "\n",
    "# Evaluate on test set\n",
    "model.eval()\n",
    "all_preds = []\n",
    "all_labels = []\n",
    "\n",
    "with torch.no_grad():\n",
    "    for images, labels in tqdm(test_loader, desc='Testing'):\n",
    "        images, labels = images.to(device), labels.to(device)\n",
    "        outputs = model(images)\n",
    "        _, predicted = torch.max(outputs, 1)\n",
    "        all_preds.extend(predicted.cpu().numpy())\n",
    "        all_labels.extend(labels.cpu().numpy())\n",
    "\n",
    "# Define y_true and y_pred for evaluation\n",
    "y_true = all_labels\n",
    "y_pred = all_preds\n",
    "\n",
    "# Calculate and print overall accuracy score\n",
    "accuracy = accuracy_score(y_true, y_pred)\n",
    "\n",
    "# #region agent log\n",
    "log_debug('train_gru.ipynb:21', 'Test accuracy calculation', {\n",
    "    'accuracy': float(accuracy),\n",
    "    'accuracy_percent': float(accuracy * 100),\n",
    "    'total_samples': len(y_true),\n",
    "    'correct_predictions': sum(1 for i in range(len(y_true)) if y_true[i] == y_pred[i]),\n",
    "    'incorrect_predictions': sum(1 for i in range(len(y_true)) if y_true[i] != y_pred[i]),\n",
    "    'y_true_sample': y_true[:10],\n",
    "    'y_pred_sample': y_pred[:10]\n",
    "}, 'D')\n",
    "# #endregion\n",
    "\n",
    "print(f\"\\nOverall Accuracy Score: {accuracy:.4f} ({accuracy*100:.2f}%)\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 9. Confusion Matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Generate confusion matrix using y_true and y_pred\n",
    "cm = confusion_matrix(y_true, y_pred)\n",
    "\n",
    "# Plot confusion matrix\n",
    "plt.figure(figsize=(10, 8))\n",
    "sns.heatmap(cm, annot=True, fmt='d', cmap='Blues', \n",
    "            xticklabels=CLASS_NAMES, yticklabels=CLASS_NAMES,\n",
    "            cbar_kws={'label': 'Count'})\n",
    "plt.title('Confusion Matrix - GRU Model', fontsize=16, fontweight='bold', pad=20)\n",
    "plt.xlabel('Predicted Label', fontsize=12)\n",
    "plt.ylabel('True Label', fontsize=12)\n",
    "plt.xticks(rotation=45, ha='right')\n",
    "plt.yticks(rotation=0)\n",
    "plt.tight_layout()\n",
    "plt.savefig(os.path.join(MODEL_DIR, 'gru_confusion_matrix.png'), dpi=300, bbox_inches='tight')\n",
    "plt.show()\n",
    "\n",
    "# Print confusion matrix as table\n",
    "print(\"\\nConfusion Matrix:\")\n",
    "print(f\"{'':<15}\", end='')\n",
    "for name in CLASS_NAMES:\n",
    "    print(f\"{name:<15}\", end='')\n",
    "print()\n",
    "for i, name in enumerate(CLASS_NAMES):\n",
    "    print(f\"{name:<15}\", end='')\n",
    "    for j in range(len(CLASS_NAMES)):\n",
    "        print(f\"{cm[i][j]:<15}\", end='')\n",
    "    print()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 10. Classification Report"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculate and print the full classification report (showing precision, recall, and f1-score for all classes)\n",
    "print(\"Full Classification Report:\")\n",
    "print(\"=\" * 70)\n",
    "print(classification_report(y_true, y_pred, target_names=CLASS_NAMES))\n",
    "print(\"=\" * 70)\n",
    "\n",
    "# Also generate report as dictionary for detailed access\n",
    "report = classification_report(y_true, y_pred, \n",
    "                                target_names=CLASS_NAMES, \n",
    "                                output_dict=True)\n",
    "\n",
    "print(\"Classification Report:\")\n",
    "print(\"=\" * 70)\n",
    "print(f\"{'Class':<15} {'Precision':<12} {'Recall':<12} {'F1-Score':<12} {'Support':<10}\")\n",
    "print(\"-\" * 70)\n",
    "\n",
    "for class_name in CLASS_NAMES:\n",
    "    metrics = report[class_name]\n",
    "    print(f\"{class_name:<15} {metrics['precision']:<12.4f} {metrics['recall']:<12.4f} \"\n",
    "          f\"{metrics['f1-score']:<12.4f} {int(metrics['support']):<10})\")\n",
    "\n",
    "print(\"-\" * 70)\n",
    "print(f\"{'Accuracy':<15} {'':<12} {'':<12} {report['accuracy']:<12.4f} {len(y_true):<10}\")\n",
    "print(f\"{'Macro Avg':<15} {report['macro avg']['precision']:<12.4f} \"\n",
    "      f\"{report['macro avg']['recall']:<12.4f} {report['macro avg']['f1-score']:<12.4f} \"\n",
    "      f\"{int(report['macro avg']['support']):<10}\")\n",
    "print(f\"{'Weighted Avg':<15} {report['weighted avg']['precision']:<12.4f} \"\n",
    "      f\"{report['weighted avg']['recall']:<12.4f} {report['weighted avg']['f1-score']:<12.4f} \"\n",
    "      f\"{int(report['weighted avg']['support']):<10}\")\n",
    "print(\"=\" * 70)\n",
    "\n",
    "# Save report to file\n",
    "report_path = os.path.join(MODEL_DIR, 'gru_classification_report.txt')\n",
    "with open(report_path, 'w') as f:\n",
    "    f.write(classification_report(y_true, y_pred, target_names=CLASS_NAMES))\n",
    "print(f\"\\nClassification report saved to {report_path}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 11. Sample Predictions Visualization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visualize sample predictions\n",
    "model.eval()\n",
    "fig, axes = plt.subplots(2, 5, figsize=(20, 8))\n",
    "axes = axes.ravel()\n",
    "\n",
    "# Get a batch of test images\n",
    "dataiter = iter(test_loader)\n",
    "images, labels = next(dataiter)\n",
    "images = images.to(device)\n",
    "\n",
    "with torch.no_grad():\n",
    "    outputs = model(images)\n",
    "    _, predicted = torch.max(outputs, 1)\n",
    "    probabilities = torch.nn.functional.softmax(outputs, dim=1)\n",
    "\n",
    "# Denormalize for visualization\n",
    "mean = torch.tensor([0.485, 0.456, 0.406]).view(3, 1, 1)\n",
    "std = torch.tensor([0.229, 0.224, 0.225]).view(3, 1, 1)\n",
    "\n",
    "for idx in range(min(10, len(images))):\n",
    "    img = images[idx].cpu()\n",
    "    img = img * std + mean  # Denormalize\n",
    "    img = torch.clamp(img, 0, 1)\n",
    "    img = img.permute(1, 2, 0).numpy()\n",
    "    \n",
    "    true_label = CLASS_NAMES[labels[idx]]\n",
    "    pred_label = CLASS_NAMES[predicted[idx]]\n",
    "    confidence = probabilities[idx][predicted[idx]].item() * 100\n",
    "    \n",
    "    # Color: green if correct, red if wrong\n",
    "    color = 'green' if predicted[idx] == labels[idx] else 'red'\n",
    "    \n",
    "    axes[idx].imshow(img)\n",
    "    axes[idx].set_title(f'True: {true_label}\\nPred: {pred_label} ({confidence:.1f}%)', \n",
    "                        color=color, fontsize=10, fontweight='bold')\n",
    "    axes[idx].axis('off')\n",
    "\n",
    "plt.suptitle('Sample Predictions on Test Set', fontsize=16, fontweight='bold', y=1.02)\n",
    "plt.tight_layout()\n",
    "plt.savefig(os.path.join(MODEL_DIR, 'gru_sample_predictions.png'), dpi=300, bbox_inches='tight')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 12. Summary\n",
    "\n",
    "### Model Performance Summary:\n",
    "- **Test Accuracy**: Calculated above\n",
    "- **Best Validation Accuracy**: Calculated above\n",
    "- **Model saved to**: `models/gru/gru_brain_tumor_classifier.pth`\n",
    "- **Training history saved to**: `models/gru/gru_training_history.csv`\n",
    "\n",
    "### Files Generated:\n",
    "1. Trained model: `models/gru/gru_brain_tumor_classifier.pth`\n",
    "2. Training history: `models/gru/gru_training_history.csv`\n",
    "3. Training curves: `models/gru/gru_training_curves.png`\n",
    "4. Confusion matrix: `models/gru/gru_confusion_matrix.png`\n",
    "5. Classification report: `models/gru/gru_classification_report.txt`\n",
    "6. Sample predictions: `models/gru/gru_sample_predictions.png`\n",
    "\n",
    "All files are saved in the `models/gru/` directory and can be used for reporting and further analysis.\n",
    "\n",
    "### GRU vs LSTM:\n",
    "- **GRU** is generally faster and uses less memory than LSTM\n",
    "- **GRU** has fewer parameters (no cell state, only hidden state)\n",
    "- **LSTM** may capture longer dependencies but GRU often performs similarly with better efficiency\n",
    "- Both architectures are available for comparison: `train_rnn_lstm.ipynb` and `train_gru.ipynb`"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "deep-mric",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
