{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# RNN with GRU Model Training for Brain Tumor Classification\n",
    "\n",
    "This notebook trains a hybrid CNN-GRU model to classify brain MRI images into 4 categories:\n",
    "- **NO_TUMOR**: Healthy brain (no tumor detected)\n",
    "- **GLIOMA**: Glioma tumor type\n",
    "- **MENINGIOMA**: Meningioma tumor type\n",
    "- **PITUITARY**: Pituitary tumor type\n",
    "\n",
    "## Overview\n",
    "\n",
    "This notebook implements a **CNN-GRU hybrid architecture**:\n",
    "1. **CNN Feature Extractor**: Extracts spatial features from images using convolutional layers\n",
    "2. **GRU Layers**: Processes the extracted features as sequences (GRU is faster and more efficient than LSTM)\n",
    "3. **Fully Connected Layers**: Final classification into 4 classes\n",
    "\n",
    "This approach combines the spatial feature extraction capabilities of CNNs with the sequential modeling power of GRUs.\n",
    "\n",
    "## Requirements\n",
    "\n",
    "Make sure you have installed all required packages:\n",
    "```bash\n",
    "pip install torch torchvision seaborn pandas scikit-learn matplotlib numpy tqdm\n",
    "```\n",
    "\n",
    "Or install from requirements.txt:\n",
    "```bash\n",
    "pip install -r requirements.txt\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Setup and Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torch.utils.data import DataLoader\n",
    "import torchvision.transforms as transforms\n",
    "from torchvision.datasets import ImageFolder\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from sklearn.metrics import confusion_matrix, classification_report, accuracy_score\n",
    "from tqdm import tqdm\n",
    "import os\n",
    "import random\n",
    "from pathlib import Path\n",
    "\n",
    "# Set random seeds for reproducibility\n",
    "def set_seed(seed=42):\n",
    "    random.seed(seed)\n",
    "    np.random.seed(seed)\n",
    "    torch.manual_seed(seed)\n",
    "    torch.cuda.manual_seed_all(seed)\n",
    "    torch.backends.cudnn.deterministic = True\n",
    "    torch.backends.cudnn.benchmark = False\n",
    "\n",
    "set_seed(42)\n",
    "\n",
    "# Set device\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "print(f'Using device: {device}')\n",
    "if torch.cuda.is_available():\n",
    "    print(f'GPU: {torch.cuda.get_device_name(0)}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Configuration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Configuration\n",
    "DATA_DIR = 'data/vgg16_classification'\n",
    "MODEL_DIR = 'models/gru'\n",
    "MODEL_SAVE_PATH = os.path.join(MODEL_DIR, 'gru_brain_tumor_classifier.pth')\n",
    "HISTORY_SAVE_PATH = os.path.join(MODEL_DIR, 'gru_training_history.csv')\n",
    "\n",
    "# Training hyperparameters\n",
    "BATCH_SIZE = 32\n",
    "LEARNING_RATE = 0.001\n",
    "NUM_EPOCHS = 50\n",
    "NUM_CLASSES = 4\n",
    "\n",
    "# Class names\n",
    "CLASS_NAMES = ['NO_TUMOR', 'GLIOMA', 'MENINGIOMA', 'PITUITARY']\n",
    "\n",
    "# Create models directory if it doesn't exist\n",
    "os.makedirs(MODEL_DIR, exist_ok=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Data Loading and Preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Data transforms\n",
    "# Training: only normalization (augmentation already applied via augment_training_data.py)\n",
    "# Use train_augmented directory which contains pre-augmented images\n",
    "train_transform = transforms.Compose([\n",
    "    transforms.Resize((224, 224)),\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225])\n",
    "])\n",
    "\n",
    "# Validation/Test: only normalization (no augmentation)\n",
    "val_test_transform = transforms.Compose([\n",
    "    transforms.Resize((224, 224)),\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225])\n",
    "])\n",
    "\n",
    "# Load datasets\n",
    "# Use train_augmented directory (created by augment_training_data.py)\n",
    "# If train_augmented doesn't exist, fall back to train directory\n",
    "train_dir = os.path.join(DATA_DIR, 'train_augmented')\n",
    "if not os.path.exists(train_dir):\n",
    "    print(f\"Warning: {train_dir} not found. Using 'train' directory instead.\")\n",
    "    print(\"Run 'python augment_training_data.py' first to create augmented training data.\")\n",
    "    train_dir = os.path.join(DATA_DIR, 'train')\n",
    "train_dataset = ImageFolder(root=train_dir, transform=train_transform)\n",
    "val_dataset = ImageFolder(root=os.path.join(DATA_DIR, 'val'), transform=val_test_transform)\n",
    "test_dataset = ImageFolder(root=os.path.join(DATA_DIR, 'test'), transform=val_test_transform)\n",
    "\n",
    "# Create data loaders\n",
    "train_loader = DataLoader(train_dataset, batch_size=BATCH_SIZE, shuffle=True, num_workers=2)\n",
    "val_loader = DataLoader(val_dataset, batch_size=BATCH_SIZE, shuffle=False, num_workers=2)\n",
    "test_loader = DataLoader(test_dataset, batch_size=BATCH_SIZE, shuffle=False, num_workers=2)\n",
    "\n",
    "print(f'Train samples: {len(train_dataset)}')\n",
    "print(f'Validation samples: {len(val_dataset)}')\n",
    "print(f'Test samples: {len(test_dataset)}')\n",
    "print(f'Number of classes: {len(train_dataset.classes)}')\n",
    "print(f'Class names: {train_dataset.classes}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.1 Class Distribution"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Display class distribution\n",
    "def get_class_distribution(dataset):\n",
    "    class_counts = {}\n",
    "    for _, label in dataset:\n",
    "        class_name = dataset.classes[label]\n",
    "        class_counts[class_name] = class_counts.get(class_name, 0) + 1\n",
    "    return class_counts\n",
    "\n",
    "train_dist = get_class_distribution(train_dataset)\n",
    "val_dist = get_class_distribution(val_dataset)\n",
    "test_dist = get_class_distribution(test_dataset)\n",
    "\n",
    "# Create visualization\n",
    "fig, axes = plt.subplots(1, 3, figsize=(18, 5))\n",
    "\n",
    "for idx, (dist, title) in enumerate([(train_dist, 'Train'), (val_dist, 'Validation'), (test_dist, 'Test')]):\n",
    "    classes = list(dist.keys())\n",
    "    counts = list(dist.values())\n",
    "    axes[idx].bar(classes, counts, color=['#1f77b4', '#ff7f0e', '#2ca02c', '#d62728'])\n",
    "    axes[idx].set_title(f'{title} Set Class Distribution', fontsize=14, fontweight='bold')\n",
    "    axes[idx].set_xlabel('Class', fontsize=12)\n",
    "    axes[idx].set_ylabel('Number of Samples', fontsize=12)\n",
    "    axes[idx].tick_params(axis='x', rotation=45)\n",
    "    for i, v in enumerate(counts):\n",
    "        axes[idx].text(i, v, str(v), ha='center', va='bottom')\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "# Print summary\n",
    "print(\"\\nClass Distribution Summary:\")\n",
    "print(f\"{'Class':<15} {'Train':<10} {'Val':<10} {'Test':<10}\")\n",
    "print(\"-\" * 50)\n",
    "for class_name in CLASS_NAMES:\n",
    "    print(f\"{class_name:<15} {train_dist.get(class_name, 0):<10} {val_dist.get(class_name, 0):<10} {test_dist.get(class_name, 0):<10}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. CNN-GRU Model Architecture"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class BrainTumorCNNGRU(nn.Module):\n",
    "    def __init__(self, num_classes=4):\n",
    "        super(BrainTumorCNNGRU, self).__init__()\n",
    "        \n",
    "        # CNN Feature Extractor\n",
    "        self.conv1 = nn.Sequential(\n",
    "            nn.Conv2d(3, 32, kernel_size=3, padding=1),\n",
    "            nn.BatchNorm2d(32),\n",
    "            nn.ReLU(inplace=True),\n",
    "            nn.Conv2d(32, 32, kernel_size=3, padding=1),\n",
    "            nn.BatchNorm2d(32),\n",
    "            nn.ReLU(inplace=True),\n",
    "            nn.MaxPool2d(kernel_size=2, stride=2)\n",
    "        )\n",
    "        \n",
    "        self.conv2 = nn.Sequential(\n",
    "            nn.Conv2d(32, 64, kernel_size=3, padding=1),\n",
    "            nn.BatchNorm2d(64),\n",
    "            nn.ReLU(inplace=True),\n",
    "            nn.Conv2d(64, 64, kernel_size=3, padding=1),\n",
    "            nn.BatchNorm2d(64),\n",
    "            nn.ReLU(inplace=True),\n",
    "            nn.MaxPool2d(kernel_size=2, stride=2)\n",
    "        )\n",
    "        \n",
    "        self.conv3 = nn.Sequential(\n",
    "            nn.Conv2d(64, 128, kernel_size=3, padding=1),\n",
    "            nn.BatchNorm2d(128),\n",
    "            nn.ReLU(inplace=True),\n",
    "            nn.Conv2d(128, 128, kernel_size=3, padding=1),\n",
    "            nn.BatchNorm2d(128),\n",
    "            nn.ReLU(inplace=True),\n",
    "            nn.MaxPool2d(kernel_size=2, stride=2)\n",
    "        )\n",
    "        \n",
    "        # Adaptive pooling to get fixed size feature maps\n",
    "        self.adaptive_pool = nn.AdaptiveAvgPool2d((7, 7))\n",
    "        \n",
    "        # Flatten spatial dimensions for GRU\n",
    "        # After pooling: 128 channels * 7 * 7 = 6272 features\n",
    "        self.feature_size = 128 * 7 * 7\n",
    "        \n",
    "        # GRU layers (GRU is faster and more efficient than LSTM)\n",
    "        self.gru = nn.GRU(input_size=self.feature_size, hidden_size=256, \n",
    "                         num_layers=2, batch_first=True, dropout=0.3)\n",
    "        \n",
    "        # Fully connected layers\n",
    "        self.fc = nn.Sequential(\n",
    "            nn.Dropout(0.5),\n",
    "            nn.Linear(256, 128),\n",
    "            nn.ReLU(inplace=True),\n",
    "            nn.Dropout(0.5),\n",
    "            nn.Linear(128, num_classes)\n",
    "        )\n",
    "        \n",
    "    def forward(self, x):\n",
    "        # CNN feature extraction\n",
    "        x = self.conv1(x)\n",
    "        x = self.conv2(x)\n",
    "        x = self.conv3(x)\n",
    "        x = self.adaptive_pool(x)\n",
    "        \n",
    "        # Reshape for GRU: (batch, channels, height, width) -> (batch, seq_len, features)\n",
    "        batch_size = x.size(0)\n",
    "        x = x.view(batch_size, -1, self.feature_size)  # (batch, 1, feature_size)\n",
    "        \n",
    "        # GRU processing\n",
    "        gru_out, h_n = self.gru(x)\n",
    "        # Use the last output\n",
    "        gru_out = gru_out[:, -1, :]  # (batch, hidden_size)\n",
    "        \n",
    "        # Classification\n",
    "        x = self.fc(gru_out)\n",
    "        return x\n",
    "\n",
    "# Initialize model\n",
    "model = BrainTumorCNNGRU(num_classes=NUM_CLASSES).to(device)\n",
    "\n",
    "# Print model architecture\n",
    "print(\"CNN-GRU Model Architecture:\")\n",
    "print(model)\n",
    "\n",
    "# Count parameters\n",
    "total_params = sum(p.numel() for p in model.parameters())\n",
    "trainable_params = sum(p.numel() for p in model.parameters() if p.requires_grad)\n",
    "print(f\"\\nTotal parameters: {total_params:,}\")\n",
    "print(f\"Trainable parameters: {trainable_params:,}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5. Training Configuration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Loss function\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "\n",
    "# Optimizer\n",
    "optimizer = optim.Adam(model.parameters(), lr=LEARNING_RATE, weight_decay=1e-5)\n",
    "\n",
    "# Learning rate scheduler\n",
    "scheduler = optim.lr_scheduler.ReduceLROnPlateau(optimizer, mode='min', factor=0.5, patience=5, verbose=True)\n",
    "\n",
    "print(f\"Loss function: CrossEntropyLoss\")\n",
    "print(f\"Optimizer: Adam (lr={LEARNING_RATE})\")\n",
    "print(f\"Learning rate scheduler: ReduceLROnPlateau\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 6. Training Loop"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_epoch(model, loader, criterion, optimizer, device):\n",
    "    model.train()\n",
    "    running_loss = 0.0\n",
    "    correct = 0\n",
    "    total = 0\n",
    "    \n",
    "    for images, labels in tqdm(loader, desc='Training'):\n",
    "        images, labels = images.to(device), labels.to(device)\n",
    "        \n",
    "        # Forward pass\n",
    "        optimizer.zero_grad()\n",
    "        outputs = model(images)\n",
    "        loss = criterion(outputs, labels)\n",
    "        \n",
    "        # Backward pass\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        \n",
    "        # Statistics\n",
    "        running_loss += loss.item()\n",
    "        _, predicted = torch.max(outputs.data, 1)\n",
    "        total += labels.size(0)\n",
    "        correct += (predicted == labels).sum().item()\n",
    "    \n",
    "    epoch_loss = running_loss / len(loader)\n",
    "    epoch_acc = 100 * correct / total\n",
    "    return epoch_loss, epoch_acc\n",
    "\n",
    "def validate_epoch(model, loader, criterion, device):\n",
    "    model.eval()\n",
    "    running_loss = 0.0\n",
    "    correct = 0\n",
    "    total = 0\n",
    "    \n",
    "    with torch.no_grad():\n",
    "        for images, labels in tqdm(loader, desc='Validating'):\n",
    "            images, labels = images.to(device), labels.to(device)\n",
    "            \n",
    "            outputs = model(images)\n",
    "            loss = criterion(outputs, labels)\n",
    "            \n",
    "            running_loss += loss.item()\n",
    "            _, predicted = torch.max(outputs.data, 1)\n",
    "            total += labels.size(0)\n",
    "            correct += (predicted == labels).sum().item()\n",
    "    \n",
    "    epoch_loss = running_loss / len(loader)\n",
    "    epoch_acc = 100 * correct / total\n",
    "    return epoch_loss, epoch_acc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Training history\n",
    "history = {\n",
    "    'train_loss': [],\n",
    "    'train_acc': [],\n",
    "    'val_loss': [],\n",
    "    'val_acc': []\n",
    "}\n",
    "\n",
    "best_val_acc = 0.0\n",
    "patience_counter = 0\n",
    "early_stopping_patience = 10\n",
    "\n",
    "print(\"Starting training...\")\n",
    "print(f\"Training for {NUM_EPOCHS} epochs\")\n",
    "print(\"-\" * 60)\n",
    "\n",
    "for epoch in range(NUM_EPOCHS):\n",
    "    print(f\"\\nEpoch {epoch+1}/{NUM_EPOCHS}\")\n",
    "    \n",
    "    # Train\n",
    "    train_loss, train_acc = train_epoch(model, train_loader, criterion, optimizer, device)\n",
    "    \n",
    "    # Validate\n",
    "    val_loss, val_acc = validate_epoch(model, val_loader, criterion, device)\n",
    "    \n",
    "    # Update learning rate\n",
    "    scheduler.step(val_loss)\n",
    "    \n",
    "    # Save history\n",
    "    history['train_loss'].append(train_loss)\n",
    "    history['train_acc'].append(train_acc)\n",
    "    history['val_loss'].append(val_loss)\n",
    "    history['val_acc'].append(val_acc)\n",
    "    \n",
    "    # Print epoch results\n",
    "    print(f\"Train Loss: {train_loss:.4f}, Train Acc: {train_acc:.2f}%\")\n",
    "    print(f\"Val Loss: {val_loss:.4f}, Val Acc: {val_acc:.2f}%\")\n",
    "    print(f\"Learning Rate: {optimizer.param_groups[0]['lr']:.6f}\")\n",
    "    \n",
    "    # Save best model\n",
    "    if val_acc > best_val_acc:\n",
    "        best_val_acc = val_acc\n",
    "        torch.save({\n",
    "            'epoch': epoch + 1,\n",
    "            'model_state_dict': model.state_dict(),\n",
    "            'optimizer_state_dict': optimizer.state_dict(),\n",
    "            'val_acc': val_acc,\n",
    "            'history': history\n",
    "        }, MODEL_SAVE_PATH)\n",
    "        print(f\"Saved best model (Val Acc: {val_acc:.2f}%)\")\n",
    "        patience_counter = 0\n",
    "    else:\n",
    "        patience_counter += 1\n",
    "    \n",
    "    # Early stopping\n",
    "    if patience_counter >= early_stopping_patience:\n",
    "        print(f\"\\nEarly stopping triggered after {epoch+1} epochs\")\n",
    "        break\n",
    "\n",
    "print(\"\\n\" + \"=\" * 60)\n",
    "print(\"Training completed!\")\n",
    "print(f\"Best validation accuracy: {best_val_acc:.2f}%\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 6.1 Save Training History"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save training history to CSV\n",
    "history_df = pd.DataFrame(history)\n",
    "history_df.to_csv(HISTORY_SAVE_PATH, index=False)\n",
    "print(f\"Training history saved to {HISTORY_SAVE_PATH}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 7. Training Curves Visualization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot training curves\n",
    "fig, axes = plt.subplots(1, 2, figsize=(15, 5))\n",
    "\n",
    "# Loss curve\n",
    "axes[0].plot(history['train_loss'], label='Train Loss', linewidth=2)\n",
    "axes[0].plot(history['val_loss'], label='Validation Loss', linewidth=2)\n",
    "axes[0].set_xlabel('Epoch', fontsize=12)\n",
    "axes[0].set_ylabel('Loss', fontsize=12)\n",
    "axes[0].set_title('Training and Validation Loss', fontsize=14, fontweight='bold')\n",
    "axes[0].legend()\n",
    "axes[0].grid(True, alpha=0.3)\n",
    "\n",
    "# Accuracy curve\n",
    "axes[1].plot(history['train_acc'], label='Train Accuracy', linewidth=2)\n",
    "axes[1].plot(history['val_acc'], label='Validation Accuracy', linewidth=2)\n",
    "axes[1].set_xlabel('Epoch', fontsize=12)\n",
    "axes[1].set_ylabel('Accuracy (%)', fontsize=12)\n",
    "axes[1].set_title('Training and Validation Accuracy', fontsize=14, fontweight='bold')\n",
    "axes[1].legend()\n",
    "axes[1].grid(True, alpha=0.3)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.savefig(os.path.join(MODEL_DIR, 'gru_training_curves.png'), dpi=300, bbox_inches='tight')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 8. Load Best Model and Evaluate on Test Set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load best model\n",
    "checkpoint = torch.load(MODEL_SAVE_PATH)\n",
    "model.load_state_dict(checkpoint['model_state_dict'])\n",
    "print(f\"Loaded best model from epoch {checkpoint['epoch']}\")\n",
    "print(f\"Best validation accuracy: {checkpoint['val_acc']:.2f}%\")\n",
    "\n",
    "# Evaluate on test set\n",
    "model.eval()\n",
    "all_preds = []\n",
    "all_labels = []\n",
    "\n",
    "with torch.no_grad():\n",
    "    for images, labels in tqdm(test_loader, desc='Testing'):\n",
    "        images, labels = images.to(device), labels.to(device)\n",
    "        outputs = model(images)\n",
    "        _, predicted = torch.max(outputs, 1)\n",
    "        all_preds.extend(predicted.cpu().numpy())\n",
    "        all_labels.extend(labels.cpu().numpy())\n",
    "\n",
    "# Define y_true and y_pred for evaluation\n",
    "y_true = all_labels\n",
    "y_pred = all_preds\n",
    "\n",
    "# Calculate and print overall accuracy score\n",
    "accuracy = accuracy_score(y_true, y_pred)\n",
    "print(f\"\\nOverall Accuracy Score: {accuracy:.4f} ({accuracy*100:.2f}%)\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 9. Confusion Matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Generate confusion matrix using y_true and y_pred\n",
    "cm = confusion_matrix(y_true, y_pred)\n",
    "\n",
    "# Plot confusion matrix\n",
    "plt.figure(figsize=(10, 8))\n",
    "sns.heatmap(cm, annot=True, fmt='d', cmap='Blues', \n",
    "            xticklabels=CLASS_NAMES, yticklabels=CLASS_NAMES,\n",
    "            cbar_kws={'label': 'Count'})\n",
    "plt.title('Confusion Matrix - GRU Model', fontsize=16, fontweight='bold', pad=20)\n",
    "plt.xlabel('Predicted Label', fontsize=12)\n",
    "plt.ylabel('True Label', fontsize=12)\n",
    "plt.xticks(rotation=45, ha='right')\n",
    "plt.yticks(rotation=0)\n",
    "plt.tight_layout()\n",
    "plt.savefig(os.path.join(MODEL_DIR, 'gru_confusion_matrix.png'), dpi=300, bbox_inches='tight')\n",
    "plt.show()\n",
    "\n",
    "# Print confusion matrix as table\n",
    "print(\"\\nConfusion Matrix:\")\n",
    "print(f\"{'':<15}\", end='')\n",
    "for name in CLASS_NAMES:\n",
    "    print(f\"{name:<15}\", end='')\n",
    "print()\n",
    "for i, name in enumerate(CLASS_NAMES):\n",
    "    print(f\"{name:<15}\", end='')\n",
    "    for j in range(len(CLASS_NAMES)):\n",
    "        print(f\"{cm[i][j]:<15}\", end='')\n",
    "    print()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 10. Classification Report"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculate and print the full classification report (showing precision, recall, and f1-score for all classes)\n",
    "print(\"Full Classification Report:\")\n",
    "print(\"=\" * 70)\n",
    "print(classification_report(y_true, y_pred, target_names=CLASS_NAMES))\n",
    "print(\"=\" * 70)\n",
    "\n",
    "# Also generate report as dictionary for detailed access\n",
    "report = classification_report(y_true, y_pred, \n",
    "                                target_names=CLASS_NAMES, \n",
    "                                output_dict=True)\n",
    "\n",
    "print(\"Classification Report:\")\n",
    "print(\"=\" * 70)\n",
    "print(f\"{'Class':<15} {'Precision':<12} {'Recall':<12} {'F1-Score':<12} {'Support':<10}\")\n",
    "print(\"-\" * 70)\n",
    "\n",
    "for class_name in CLASS_NAMES:\n",
    "    metrics = report[class_name]\n",
    "    print(f\"{class_name:<15} {metrics['precision']:<12.4f} {metrics['recall']:<12.4f} \"\n",
    "          f\"{metrics['f1-score']:<12.4f} {int(metrics['support']):<10})\")\n",
    "\n",
    "print(\"-\" * 70)\n",
    "print(f\"{'Accuracy':<15} {'':<12} {'':<12} {report['accuracy']:<12.4f} {len(y_true):<10}\")\n",
    "print(f\"{'Macro Avg':<15} {report['macro avg']['precision']:<12.4f} \"\n",
    "      f\"{report['macro avg']['recall']:<12.4f} {report['macro avg']['f1-score']:<12.4f} \"\n",
    "      f\"{int(report['macro avg']['support']):<10}\")\n",
    "print(f\"{'Weighted Avg':<15} {report['weighted avg']['precision']:<12.4f} \"\n",
    "      f\"{report['weighted avg']['recall']:<12.4f} {report['weighted avg']['f1-score']:<12.4f} \"\n",
    "      f\"{int(report['weighted avg']['support']):<10}\")\n",
    "print(\"=\" * 70)\n",
    "\n",
    "# Save report to file\n",
    "report_path = os.path.join(MODEL_DIR, 'gru_classification_report.txt')\n",
    "with open(report_path, 'w') as f:\n",
    "    f.write(classification_report(y_true, y_pred, target_names=CLASS_NAMES))\n",
    "print(f\"\\nClassification report saved to {report_path}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 11. Sample Predictions Visualization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visualize sample predictions\n",
    "model.eval()\n",
    "fig, axes = plt.subplots(2, 5, figsize=(20, 8))\n",
    "axes = axes.ravel()\n",
    "\n",
    "# Get a batch of test images\n",
    "dataiter = iter(test_loader)\n",
    "images, labels = next(dataiter)\n",
    "images = images.to(device)\n",
    "\n",
    "with torch.no_grad():\n",
    "    outputs = model(images)\n",
    "    _, predicted = torch.max(outputs, 1)\n",
    "    probabilities = torch.nn.functional.softmax(outputs, dim=1)\n",
    "\n",
    "# Denormalize for visualization\n",
    "mean = torch.tensor([0.485, 0.456, 0.406]).view(3, 1, 1)\n",
    "std = torch.tensor([0.229, 0.224, 0.225]).view(3, 1, 1)\n",
    "\n",
    "for idx in range(min(10, len(images))):\n",
    "    img = images[idx].cpu()\n",
    "    img = img * std + mean  # Denormalize\n",
    "    img = torch.clamp(img, 0, 1)\n",
    "    img = img.permute(1, 2, 0).numpy()\n",
    "    \n",
    "    true_label = CLASS_NAMES[labels[idx]]\n",
    "    pred_label = CLASS_NAMES[predicted[idx]]\n",
    "    confidence = probabilities[idx][predicted[idx]].item() * 100\n",
    "    \n",
    "    # Color: green if correct, red if wrong\n",
    "    color = 'green' if predicted[idx] == labels[idx] else 'red'\n",
    "    \n",
    "    axes[idx].imshow(img)\n",
    "    axes[idx].set_title(f'True: {true_label}\\nPred: {pred_label} ({confidence:.1f}%)', \n",
    "                        color=color, fontsize=10, fontweight='bold')\n",
    "    axes[idx].axis('off')\n",
    "\n",
    "plt.suptitle('Sample Predictions on Test Set', fontsize=16, fontweight='bold', y=1.02)\n",
    "plt.tight_layout()\n",
    "plt.savefig(os.path.join(MODEL_DIR, 'gru_sample_predictions.png'), dpi=300, bbox_inches='tight')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 12. Summary\n",
    "\n",
    "### Model Performance Summary:\n",
    "- **Test Accuracy**: Calculated above\n",
    "- **Best Validation Accuracy**: Calculated above\n",
    "- **Model saved to**: `models/gru/gru_brain_tumor_classifier.pth`\n",
    "- **Training history saved to**: `models/gru/gru_training_history.csv`\n",
    "\n",
    "### Files Generated:\n",
    "1. Trained model: `models/gru/gru_brain_tumor_classifier.pth`\n",
    "2. Training history: `models/gru/gru_training_history.csv`\n",
    "3. Training curves: `models/gru/gru_training_curves.png`\n",
    "4. Confusion matrix: `models/gru/gru_confusion_matrix.png`\n",
    "5. Classification report: `models/gru/gru_classification_report.txt`\n",
    "6. Sample predictions: `models/gru/gru_sample_predictions.png`\n",
    "\n",
    "All files are saved in the `models/gru/` directory and can be used for reporting and further analysis.\n",
    "\n",
    "### GRU vs LSTM:\n",
    "- **GRU** is generally faster and uses less memory than LSTM\n",
    "- **GRU** has fewer parameters (no cell state, only hidden state)\n",
    "- **LSTM** may capture longer dependencies but GRU often performs similarly with better efficiency\n",
    "- Both architectures are available for comparison: `train_rnn_lstm.ipynb` and `train_gru.ipynb`"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.8.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
