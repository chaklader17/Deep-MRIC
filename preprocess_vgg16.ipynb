{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# VGG16 Data Preprocessing for Brain Tumor Classification\n",
        "\n",
        "This notebook preprocesses brain MRI images for VGG16 classification model training.\n",
        "\n",
        "## Overview\n",
        "\n",
        "This preprocessing pipeline performs the following operations:\n",
        "1. **Loads raw MRI images** from organized class folders\n",
        "2. **Crops brain regions** using contour detection (removes black background)\n",
        "3. **Resizes images** to 224√ó224 (VGG16 input size)\n",
        "4. **Performs stratified train/validation/test split** (70/15/15)\n",
        "5. **Saves processed images** in organized directory structure\n",
        "\n",
        "## Expected Input Structure\n",
        "\n",
        "```\n",
        "data/raw_dataset/\n",
        "‚îú‚îÄ‚îÄ NO_TUMOR/\n",
        "‚îú‚îÄ‚îÄ GLIOMA/\n",
        "‚îú‚îÄ‚îÄ MENINGIOMA/\n",
        "‚îî‚îÄ‚îÄ PITUITARY/\n",
        "```\n",
        "\n",
        "## Output Structure\n",
        "\n",
        "```\n",
        "data/vgg16_classification/\n",
        "‚îú‚îÄ‚îÄ train/\n",
        "‚îÇ   ‚îú‚îÄ‚îÄ NO_TUMOR/\n",
        "‚îÇ   ‚îú‚îÄ‚îÄ GLIOMA/\n",
        "‚îÇ   ‚îú‚îÄ‚îÄ MENINGIOMA/\n",
        "‚îÇ   ‚îî‚îÄ‚îÄ PITUITARY/\n",
        "‚îú‚îÄ‚îÄ val/\n",
        "‚îÇ   ‚îî‚îÄ‚îÄ [same class folders]\n",
        "‚îî‚îÄ‚îÄ test/\n",
        "    ‚îî‚îÄ‚îÄ [same class folders]\n",
        "```\n",
        "\n",
        "---\n",
        "\n",
        "**Note:** This is part of the Deep-MRIC project. See README.md for the full pipeline.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 1. Configuration\n",
        "\n",
        "Set up the paths and parameters for preprocessing. You can modify these values based on your dataset.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# --- Configuration ---\n",
        "# Directory containing raw MRI images organized by class\n",
        "RAW_DATA_DIR = 'data/raw_dataset/'\n",
        "\n",
        "# Output directory for processed VGG16-ready images\n",
        "VGG_OUTPUT_DIR = 'data/vgg16_classification/'\n",
        "\n",
        "# VGG16 requires 224x224 input images\n",
        "VGG_IMG_SIZE = 224 \n",
        "\n",
        "# Train/Validation/Test split ratios\n",
        "SPLIT_RATIO = [0.70, 0.15, 0.15]  # Train:Val:Test\n",
        "\n",
        "# Expected Class Folders in RAW_DATA_DIR (Update this based on your dataset)\n",
        "CLASSES = ['NO_TUMOR', 'GLIOMA', 'MENINGIOMA', 'PITUITARY']\n",
        "SPLIT_NAMES = ['train', 'val', 'test']\n",
        "\n",
        "print(\"‚úÖ Configuration loaded!\")\n",
        "print(f\"   Input: {RAW_DATA_DIR}\")\n",
        "print(f\"   Output: {VGG_OUTPUT_DIR}\")\n",
        "print(f\"   Image Size: {VGG_IMG_SIZE}x{VGG_IMG_SIZE}\")\n",
        "print(f\"   Split Ratio: {SPLIT_RATIO[0]*100:.0f}% / {SPLIT_RATIO[1]*100:.0f}% / {SPLIT_RATIO[2]*100:.0f}%\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 2. Import Required Libraries\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "import os\n",
        "import cv2\n",
        "import numpy as np\n",
        "from tqdm import tqdm\n",
        "import shutil\n",
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "print(\"‚úÖ All libraries imported successfully!\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 3. Utility Function: Brain Region Cropping\n",
        "\n",
        "This function identifies the brain region using contour detection and crops the image to remove black background padding.\n",
        "\n",
        "**How it works:**\n",
        "1. Converts image to grayscale and applies Gaussian blur\n",
        "2. Uses thresholding to separate brain tissue from black background\n",
        "3. Applies morphological operations (erosion/dilation) to clean up\n",
        "4. Finds the largest contour (assumed to be the brain)\n",
        "5. Crops the image to the bounding box with a small buffer\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "def crop_brain_region(img):\n",
        "    \"\"\"\n",
        "    Identifies the brain region by contour detection and crops the image.\n",
        "    This effectively removes non-brain black background padding.\n",
        "    \n",
        "    Args:\n",
        "        img: Input BGR image (numpy array from cv2.imread)\n",
        "    \n",
        "    Returns:\n",
        "        Cropped image (numpy array) or None if processing fails\n",
        "    \"\"\"\n",
        "    if img is None:\n",
        "        return None\n",
        "\n",
        "    # Convert to grayscale and apply Gaussian blur to reduce noise\n",
        "    gray = cv2.cvtColor(img, cv2.COLOR_BGR2GRAY)\n",
        "    gray = cv2.GaussianBlur(gray, (5, 5), 0)\n",
        "\n",
        "    # Thresholding to separate the brain from the background\n",
        "    # Threshold value of 45 works well for MRI images with black backgrounds\n",
        "    _, thresh = cv2.threshold(gray, 45, 255, cv2.THRESH_BINARY)\n",
        "    \n",
        "    # Morphological operations to clean up the thresholded image\n",
        "    # Erosion removes small noise, dilation fills gaps\n",
        "    thresh = cv2.erode(thresh, None, iterations=2)\n",
        "    thresh = cv2.dilate(thresh, None, iterations=2)\n",
        "    \n",
        "    # Find contours (boundaries of white regions)\n",
        "    contours, _ = cv2.findContours(thresh.copy(), cv2.RETR_EXTERNAL, cv2.CHAIN_APPROX_SIMPLE)\n",
        "\n",
        "    if not contours:\n",
        "        # Fallback: if no contour found, return original image\n",
        "        print(\"Warning: No contours found, returning original image\")\n",
        "        return img \n",
        "\n",
        "    # Find the largest contour (assumed to be the brain)\n",
        "    c = max(contours, key=cv2.contourArea)\n",
        "\n",
        "    # Get bounding box (x, y, width, height)\n",
        "    x, y, w, h = cv2.boundingRect(c)\n",
        "    \n",
        "    # Crop the image with a small buffer for safety (prevents edge clipping)\n",
        "    buffer = 10\n",
        "    cropped_img = img[\n",
        "        max(0, y - buffer):y + h + buffer, \n",
        "        max(0, x - buffer):x + w + buffer\n",
        "    ]\n",
        "\n",
        "    return cropped_img\n",
        "\n",
        "print(\"‚úÖ Brain cropping function defined!\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 4. Main Preprocessing Function\n",
        "\n",
        "This function orchestrates the entire preprocessing pipeline:\n",
        "\n",
        "1. **Validates** input directory exists\n",
        "2. **Creates** output directory structure\n",
        "3. **Collects** all image files from class folders\n",
        "4. **Performs** stratified train/val/test split (ensures proportional class distribution)\n",
        "5. **Processes** each image (crop + resize)\n",
        "6. **Saves** processed images to organized folders\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "def prepare_vgg_data():\n",
        "    \"\"\"\n",
        "    Main preprocessing pipeline for VGG16 classification.\n",
        "    \n",
        "    The stratified split ensures each class is proportionally represented\n",
        "    in train, validation, and test sets.\n",
        "    \"\"\"\n",
        "    \n",
        "    # 0. Setup and Data Collection\n",
        "    \n",
        "    # Ensure raw data exists\n",
        "    if not os.path.exists(RAW_DATA_DIR):\n",
        "        print(f\"‚ùå Error: Raw data directory '{RAW_DATA_DIR}' not found.\")\n",
        "        print(f\"Please create the directory and organize your images as follows:\")\n",
        "        print(f\"  {RAW_DATA_DIR}\")\n",
        "        for class_name in CLASSES:\n",
        "            print(f\"    ‚îú‚îÄ‚îÄ {class_name}/\")\n",
        "        return\n",
        "\n",
        "    # Check if any class folders exist\n",
        "    class_found = False\n",
        "    for class_name in CLASSES:\n",
        "        class_path = os.path.join(RAW_DATA_DIR, class_name)\n",
        "        if os.path.isdir(class_path):\n",
        "            class_found = True\n",
        "            break\n",
        "    \n",
        "    if not class_found:\n",
        "        print(f\"‚ùå Error: No class folders found in '{RAW_DATA_DIR}'\")\n",
        "        print(f\"Expected folders: {', '.join(CLASSES)}\")\n",
        "        return\n",
        "\n",
        "    # Clear previous output and create the final structure\n",
        "    if os.path.exists(VGG_OUTPUT_DIR):\n",
        "        print(f\"‚ö†Ô∏è  Removing existing output directory: {VGG_OUTPUT_DIR}\")\n",
        "        shutil.rmtree(VGG_OUTPUT_DIR)\n",
        "    \n",
        "    # Create directory structure: output/split/class/\n",
        "    print(f\"üìÅ Creating output directory structure...\")\n",
        "    for split in SPLIT_NAMES:\n",
        "        for class_name in CLASSES:\n",
        "            os.makedirs(os.path.join(VGG_OUTPUT_DIR, split, class_name), exist_ok=True)\n",
        "            \n",
        "    # Collect all file paths and their classes\n",
        "    print(f\"üìÇ Collecting images from {RAW_DATA_DIR}...\")\n",
        "    all_files = []\n",
        "    for class_name in CLASSES:\n",
        "        class_path = os.path.join(RAW_DATA_DIR, class_name)\n",
        "        if os.path.isdir(class_path):\n",
        "            image_count = 0\n",
        "            for file_name in os.listdir(class_path):\n",
        "                if file_name.lower().endswith(('.jpg', '.png', '.jpeg')):\n",
        "                    all_files.append((os.path.join(class_path, file_name), class_name))\n",
        "                    image_count += 1\n",
        "            if image_count > 0:\n",
        "                print(f\"  ‚úì Found {image_count} images in {class_name}/\")\n",
        "    \n",
        "    if len(all_files) == 0:\n",
        "        print(f\"‚ùå Error: No image files found in {RAW_DATA_DIR}\")\n",
        "        print(\"Supported formats: .jpg, .jpeg, .png\")\n",
        "        return\n",
        "    \n",
        "    # 1. Stratified Train/Val/Test Split\n",
        "    \n",
        "    print(f\"\\nüìä Performing stratified train/val/test split...\")\n",
        "    file_paths = [f[0] for f in all_files]\n",
        "    class_labels = [f[1] for f in all_files]\n",
        "    \n",
        "    # Split 1: Train vs (Val + Test)\n",
        "    # This ensures proportional class distribution in training set\n",
        "    train_paths, temp_paths, train_labels, temp_labels = train_test_split(\n",
        "        file_paths, class_labels, \n",
        "        train_size=SPLIT_RATIO[0], \n",
        "        stratify=class_labels, \n",
        "        random_state=42  # Fixed seed for reproducibility\n",
        "    )\n",
        "    \n",
        "    # Split 2: Val vs Test\n",
        "    # Calculate ratio for second split\n",
        "    val_test_ratio = SPLIT_RATIO[2] / (SPLIT_RATIO[1] + SPLIT_RATIO[2])\n",
        "    val_paths, test_paths, val_labels, test_labels = train_test_split(\n",
        "        temp_paths, temp_labels, \n",
        "        test_size=val_test_ratio, \n",
        "        stratify=temp_labels, \n",
        "        random_state=42\n",
        "    )\n",
        "\n",
        "    splits = {\n",
        "        'train': list(zip(train_paths, train_labels)), \n",
        "        'val': list(zip(val_paths, val_labels)), \n",
        "        'test': list(zip(test_paths, test_labels))\n",
        "    }\n",
        "\n",
        "    print(f\"\\nüìà Dataset Statistics:\")\n",
        "    print(f\"  Total Images: {len(all_files)}\")\n",
        "    print(f\"  Train: {len(train_paths)} ({len(train_paths)/len(all_files)*100:.1f}%)\")\n",
        "    print(f\"  Val:   {len(val_paths)} ({len(val_paths)/len(all_files)*100:.1f}%)\")\n",
        "    print(f\"  Test:  {len(test_paths)} ({len(test_paths)/len(all_files)*100:.1f}%)\")\n",
        "\n",
        "    # 2. Process and Save Files\n",
        "    \n",
        "    print(f\"\\nüîÑ Processing images...\")\n",
        "    failed_count = 0\n",
        "    \n",
        "    for split_name, file_list in splits.items():\n",
        "        print(f\"\\n  Processing {split_name} set ({len(file_list)} images)...\")\n",
        "        for file_path, class_name in tqdm(file_list, desc=f\"  {split_name}\"):\n",
        "            \n",
        "            # Read image\n",
        "            img = cv2.imread(file_path)\n",
        "            \n",
        "            if img is None:\n",
        "                print(f\"\\n‚ö†Ô∏è  Warning: Failed to read image {file_path}. Skipping.\")\n",
        "                failed_count += 1\n",
        "                continue\n",
        "            \n",
        "            # Step 1: Crop the brain region (remove black background)\n",
        "            cleaned_img = crop_brain_region(img)\n",
        "            \n",
        "            if cleaned_img is None:\n",
        "                print(f\"\\n‚ö†Ô∏è  Warning: Failed to process image {file_path}. Skipping.\")\n",
        "                failed_count += 1\n",
        "                continue\n",
        "\n",
        "            # Step 2: Resize image to VGG-specific size (224x224)\n",
        "            # VGG16 was trained on ImageNet with 224x224 images\n",
        "            vgg_img = cv2.resize(cleaned_img, (VGG_IMG_SIZE, VGG_IMG_SIZE))\n",
        "            \n",
        "            # Step 3: Save the image into the final directory\n",
        "            final_dir = os.path.join(VGG_OUTPUT_DIR, split_name, class_name)\n",
        "            output_path = os.path.join(final_dir, os.path.basename(file_path))\n",
        "            \n",
        "            # Save with same extension as original\n",
        "            success = cv2.imwrite(output_path, vgg_img)\n",
        "            if not success:\n",
        "                print(f\"\\n‚ö†Ô∏è  Warning: Failed to save image {output_path}\")\n",
        "                failed_count += 1\n",
        "\n",
        "    print(f\"\\n‚úÖ VGG16 Preprocessing complete!\")\n",
        "    print(f\"üìÅ Output saved to: {VGG_OUTPUT_DIR}\")\n",
        "    if failed_count > 0:\n",
        "        print(f\"‚ö†Ô∏è  {failed_count} images failed to process\")\n",
        "\n",
        "print(\"‚úÖ Preprocessing function defined!\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Run the preprocessing pipeline\n",
        "prepare_vgg_data()\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 6. Verify Output (Optional)\n",
        "\n",
        "You can verify the preprocessing results by checking the output directory structure and viewing sample images.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Optional: Display directory structure and sample images\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "# Check output directory\n",
        "if os.path.exists(VGG_OUTPUT_DIR):\n",
        "    print(f\"‚úÖ Output directory exists: {VGG_OUTPUT_DIR}\\n\")\n",
        "    \n",
        "    # Count images in each split\n",
        "    for split in SPLIT_NAMES:\n",
        "        split_path = os.path.join(VGG_OUTPUT_DIR, split)\n",
        "        if os.path.exists(split_path):\n",
        "            total = 0\n",
        "            for class_name in CLASSES:\n",
        "                class_path = os.path.join(split_path, class_name)\n",
        "                if os.path.exists(class_path):\n",
        "                    count = len([f for f in os.listdir(class_path) \n",
        "                                if f.lower().endswith(('.jpg', '.png', '.jpeg'))])\n",
        "                    total += count\n",
        "                    print(f\"  {split}/{class_name}: {count} images\")\n",
        "            print(f\"  {split} Total: {total} images\\n\")\n",
        "    \n",
        "    # Display sample images (first image from train set of first class)\n",
        "    sample_class = CLASSES[0]\n",
        "    sample_dir = os.path.join(VGG_OUTPUT_DIR, 'train', sample_class)\n",
        "    if os.path.exists(sample_dir):\n",
        "        sample_files = [f for f in os.listdir(sample_dir) \n",
        "                        if f.lower().endswith(('.jpg', '.png', '.jpeg'))]\n",
        "        if sample_files:\n",
        "            sample_path = os.path.join(sample_dir, sample_files[0])\n",
        "            sample_img = cv2.imread(sample_path)\n",
        "            if sample_img is not None:\n",
        "                sample_img_rgb = cv2.cvtColor(sample_img, cv2.COLOR_BGR2RGB)\n",
        "                plt.figure(figsize=(6, 6))\n",
        "                plt.imshow(sample_img_rgb)\n",
        "                plt.title(f'Sample Processed Image\\n({sample_class}, 224√ó224)')\n",
        "                plt.axis('off')\n",
        "                plt.show()\n",
        "else:\n",
        "    print(\"‚ùå Output directory not found. Please run the preprocessing first.\")\n"
      ]
    }
  ],
  "metadata": {
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 2
}
